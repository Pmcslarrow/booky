{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMmJhTtO2FCD1vDMILVH8qi"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Importing Dataset"
      ],
      "metadata": {
        "id": "L3c5igSoT9JS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install kagglehub[pandas-datasets]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "kVvdwqPSMaoM",
        "outputId": "6cb35f12-09ae-4775-a88a-15186337fc78"
      },
      "execution_count": 259,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kagglehub[pandas-datasets] in /usr/local/lib/python3.12/dist-packages (0.3.13)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from kagglehub[pandas-datasets]) (25.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from kagglehub[pandas-datasets]) (6.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from kagglehub[pandas-datasets]) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from kagglehub[pandas-datasets]) (4.67.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from kagglehub[pandas-datasets]) (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas->kagglehub[pandas-datasets]) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->kagglehub[pandas-datasets]) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->kagglehub[pandas-datasets]) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->kagglehub[pandas-datasets]) (2025.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub[pandas-datasets]) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub[pandas-datasets]) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub[pandas-datasets]) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub[pandas-datasets]) (2025.10.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->kagglehub[pandas-datasets]) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 260,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "slTaZzDAMLUM",
        "outputId": "afbda2b2-2ecc-4b8a-bdbc-04d7531c6d0f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-885755572.py:20: DeprecationWarning: Use dataset_load() instead of load_dataset(). load_dataset() will be removed in a future version.\n",
            "  books_df = kagglehub.load_dataset(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Colab cache for faster access to the 'book-recommendation-dataset' dataset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/kagglehub/pandas_datasets.py:91: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  result = read_function(\n",
            "/tmp/ipython-input-885755572.py:26: DeprecationWarning: Use dataset_load() instead of load_dataset(). load_dataset() will be removed in a future version.\n",
            "  ratings_df = kagglehub.load_dataset(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Colab cache for faster access to the 'book-recommendation-dataset' dataset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-885755572.py:32: DeprecationWarning: Use dataset_load() instead of load_dataset(). load_dataset() will be removed in a future version.\n",
            "  users_df = kagglehub.load_dataset(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Colab cache for faster access to the 'book-recommendation-dataset' dataset.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from collections import Counter\n",
        "from google.colab import drive\n",
        "import kagglehub\n",
        "from kagglehub import KaggleDatasetAdapter\n",
        "drive.mount('/content/drive/')\n",
        "\n",
        "# Load the latest version\n",
        "books_df = kagglehub.load_dataset(\n",
        "  KaggleDatasetAdapter.PANDAS,\n",
        "  \"arashnic/book-recommendation-dataset\",\n",
        "  \"Books.csv\",\n",
        ")\n",
        "\n",
        "ratings_df = kagglehub.load_dataset(\n",
        "  KaggleDatasetAdapter.PANDAS,\n",
        "  \"arashnic/book-recommendation-dataset\",\n",
        "  \"Ratings.csv\",\n",
        ")\n",
        "\n",
        "users_df = kagglehub.load_dataset(\n",
        "  KaggleDatasetAdapter.PANDAS,\n",
        "  \"arashnic/book-recommendation-dataset\",\n",
        "  \"Users.csv\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Only keeping books with more than three ratings"
      ],
      "metadata": {
        "id": "Gc3cHdnBaBSd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(books_df.shape)\n",
        "books_df = books_df[books_df.groupby('Book-Title')['Book-Title'].transform('count') > 4]\n",
        "print(books_df.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XX05tHiWbIKN",
        "outputId": "c01cace5-e537-4c97-e2b2-ee52262529ec"
      },
      "execution_count": 261,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(271360, 8)\n",
            "(6138, 8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Joining Books, Ratings, and Users tables together"
      ],
      "metadata": {
        "id": "2MJPgJ-ea1z5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_ratings_books = pd.merge(ratings_df, books_df, on=\"ISBN\", how='inner')\n",
        "df = pd.merge(df_ratings_books, users_df, on='User-ID')\n",
        "df['User-ID'] = df['User-ID'].astype(str)\n",
        "df['Year-Of-Publication'] = pd.to_numeric(df['Year-Of-Publication'], errors='coerce')\n",
        "df = df.dropna(subset=['Year-Of-Publication'])\n",
        "df = df.dropna(subset=['Age'])\n",
        "df = df[df['Book-Rating'] > 0]\n",
        "df = df[df['Age'] <= 100]\n",
        "df = df[df['Year-Of-Publication'] > 0]\n",
        "df['Book-Rating'].describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        },
        "id": "93r6ilG_NQPw",
        "outputId": "95dd915a-1b0a-4b51-c541-01b5beadc396"
      },
      "execution_count": 262,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    20017.000000\n",
              "mean         7.919369\n",
              "std          1.767708\n",
              "min          1.000000\n",
              "25%          7.000000\n",
              "50%          8.000000\n",
              "75%          9.000000\n",
              "max         10.000000\n",
              "Name: Book-Rating, dtype: float64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Book-Rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>20017.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>7.919369</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.767708</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>7.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>8.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>9.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>10.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> float64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 262
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Combining my own data into the training set"
      ],
      "metadata": {
        "id": "u7i4lqEGb_pr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "personal_df = pd.read_csv(\"./drive/MyDrive/fine-tuning-book-set.txt\")\n",
        "end_index = len(df)\n",
        "df = pd.concat([df, personal_df], ignore_index=True, sort=False)"
      ],
      "metadata": {
        "id": "8tSGkmikGSCI"
      },
      "execution_count": 263,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "personal_df.head(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "t2gm3-hvb7L_",
        "outputId": "cfa6697b-8a51-41e4-9678-54a351695553"
      },
      "execution_count": 264,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      User-ID       ISBN  Book-Rating                 Book-Title  \\\n",
              "0  1234567890  451521951            5  The Count of Monte Cristo   \n",
              "1  1234567890  684813637            5                       1776   \n",
              "\n",
              "        Book-Author  Year-Of-Publication         Publisher  Age  \n",
              "0   Alexandre Dumas                 1844       Signet Book   23  \n",
              "1  David McCullough                 2005  Simon & Schuster   23  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-02e171fe-a6be-488b-9884-80f179f5c8bb\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>User-ID</th>\n",
              "      <th>ISBN</th>\n",
              "      <th>Book-Rating</th>\n",
              "      <th>Book-Title</th>\n",
              "      <th>Book-Author</th>\n",
              "      <th>Year-Of-Publication</th>\n",
              "      <th>Publisher</th>\n",
              "      <th>Age</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1234567890</td>\n",
              "      <td>451521951</td>\n",
              "      <td>5</td>\n",
              "      <td>The Count of Monte Cristo</td>\n",
              "      <td>Alexandre Dumas</td>\n",
              "      <td>1844</td>\n",
              "      <td>Signet Book</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1234567890</td>\n",
              "      <td>684813637</td>\n",
              "      <td>5</td>\n",
              "      <td>1776</td>\n",
              "      <td>David McCullough</td>\n",
              "      <td>2005</td>\n",
              "      <td>Simon &amp; Schuster</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-02e171fe-a6be-488b-9884-80f179f5c8bb')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-02e171fe-a6be-488b-9884-80f179f5c8bb button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-02e171fe-a6be-488b-9884-80f179f5c8bb');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-ade63e2d-9ff6-4bc5-8764-4ed4453f09ba\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ade63e2d-9ff6-4bc5-8764-4ed4453f09ba')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-ade63e2d-9ff6-4bc5-8764-4ed4453f09ba button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "personal_df",
              "summary": "{\n  \"name\": \"personal_df\",\n  \"rows\": 16,\n  \"fields\": [\n    {\n      \"column\": \"User-ID\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1234567890,\n        \"max\": 1234567890,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1234567890\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ISBN\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 189116085,\n        \"min\": 140071083,\n        \"max\": 787960756,\n        \"num_unique_values\": 16,\n        \"samples\": [\n          451521951\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Book-Rating\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 3,\n        \"max\": 5,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Book-Title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 16,\n        \"samples\": [\n          \"The Count of Monte Cristo\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Book-Author\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 11,\n        \"samples\": [\n          \"William Shakespeare\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Year-Of-Publication\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 127,\n        \"min\": 1599,\n        \"max\": 2005,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          2002\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Publisher\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 11,\n        \"samples\": [\n          \"Penguin Books\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 23,\n        \"max\": 23,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          23\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 264
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dXl51Y5OQM0e",
        "outputId": "e537bd70-122f-493a-b1e0-f28183f564fd"
      },
      "execution_count": 265,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler, MultiLabelBinarizer\n",
        "import ast\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# User Tower -- User-ID, Age\n",
        "# Item Tower -- ISBN, Book-Title, Book-Author, Publisher, Year-Of-Publication\n",
        "\n",
        "class BookRecommenderDataset(Dataset):\n",
        "    \"\"\"\n",
        "    A PyTorch Dataset class for book recommendation tasks.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    dataframe : pd.DataFrame\n",
        "        The input data containing user, item, and possibly interaction features.\n",
        "\n",
        "    Attributes\n",
        "    ----------\n",
        "    data : pd.DataFrame\n",
        "        The processed version of the input dataframe.\n",
        "    encoders : dict\n",
        "        A dictionary mapping column names to fitted label encoders.\n",
        "    reverse_encoders : dict\n",
        "        A dictionary mapping column names to reverse label encoders (index to label).\n",
        "    scalers : dict\n",
        "        A dictionary mapping column names to fitted scalers for numerical features.\n",
        "    user_item_interaction : dict\n",
        "        A dictionary mapping encoded User-IDs to a list of positive example encoded ISBNs\n",
        "    negative_examples : int\n",
        "        An integer hyperparameter for the number of negative examples to use for contrastive learning\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, data, negative_examples=1):\n",
        "        self.encoders = {} # {'Column name': {'value': idx, ...}, ...}\n",
        "        self.reverse_encoders = {} # {'Column name': {idx: 'value', ...}, ...}\n",
        "        self.scalers = {}\n",
        "        self.user_item_interactions = {} # {encoded userid: [encoded ISBN]}\n",
        "        self.negative_examples = negative_examples\n",
        "        self.data = data.sample(frac=0.20, random_state=42).reset_index(drop=True)\n",
        "        self.preprocess(self.data)\n",
        "\n",
        "    def preprocess(self, data):\n",
        "        self.encode_information()\n",
        "        self.generate_positives()\n",
        "\n",
        "    def generate_positives(self):\n",
        "        self.user_item_interaction = (\n",
        "            self.data\n",
        "            .groupby('User-ID')['ISBN']\n",
        "            .apply(list)\n",
        "            .to_dict()\n",
        "        )\n",
        "\n",
        "    def encode_information(self):\n",
        "        \"\"\"\n",
        "        Maps {key: index} pairs and StandardScaler for real valued numbers\n",
        "        \"\"\"\n",
        "        label_encoders = ['User-ID', 'ISBN', 'Book-Title', 'Book-Author', 'Publisher']\n",
        "        standard_scalers = ['Age', 'Year-Of-Publication']\n",
        "\n",
        "        for col in label_encoders:\n",
        "            unique_vals = self.data[col].astype(str).unique()\n",
        "            self.encoders[col] = {val: idx + 1 for idx, val in enumerate(unique_vals)}\n",
        "            self.reverse_encoders[col] = {idx + 1: val for idx, val in enumerate(unique_vals)}\n",
        "            self.data[col] = self.data[col].astype(str).map(self.encoders[col]).fillna(0).astype(int)\n",
        "\n",
        "        for col in standard_scalers:\n",
        "            self.scalers[col] = StandardScaler()\n",
        "            self.data[[col]] = self.scalers[col].fit_transform(self.data[[col]])\n",
        "\n",
        "        # Manually adding my own User-ID so I don't need to adjust nn.Embedding later\n",
        "        # max_user_idx = max(self.encoders['User-ID'].values())\n",
        "        # self.encoders['User-ID'][\"1234567890\"] = max_user_idx + 1\n",
        "        # self.reverse_encoders['User-ID'][max_user_idx + 1] = \"1234567890\"\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"\n",
        "        Returns\n",
        "            - user-tower data (User-ID and User-Age)\n",
        "            - positive item data (pos_item)\n",
        "            - negative item data (neg_items)\n",
        "            - Target rating\n",
        "        \"\"\"\n",
        "        positive_item = self.data.iloc[idx]\n",
        "        positive_user_id = positive_item['User-ID']\n",
        "        positive_isbns = self.user_item_interaction[positive_user_id]\n",
        "\n",
        "        negative_examples = []\n",
        "        while len(negative_examples) < self.negative_examples:\n",
        "            candidate = self.data.sample(n=1).iloc[0]\n",
        "            candidate_isbn = candidate['ISBN']\n",
        "            if candidate_isbn not in positive_isbns:\n",
        "                negative_examples.append(candidate)\n",
        "\n",
        "        output = {\n",
        "            'User-ID': torch.tensor(positive_item['User-ID'], dtype=torch.long),\n",
        "            'User-Age': torch.tensor(positive_item['Age'], dtype=torch.float32),\n",
        "            'Rating': torch.tensor(positive_item['Book-Rating'], dtype=torch.float32),\n",
        "\n",
        "            'pos_item': {\n",
        "                'Book-ISBN': torch.tensor(positive_item['ISBN'], dtype=torch.long),\n",
        "                'Book-Title': torch.tensor(positive_item['Book-Title'], dtype=torch.long),\n",
        "                'Book-Author': torch.tensor(positive_item['Book-Author'], dtype=torch.long),\n",
        "                'Book-Publisher': torch.tensor(positive_item['Publisher'], dtype=torch.long),\n",
        "                'Book-Year-Of-Publication': torch.tensor(positive_item['Year-Of-Publication'], dtype=torch.float32),\n",
        "            },\n",
        "\n",
        "            'neg_items': [\n",
        "                {\n",
        "                    'Book-ISBN': torch.tensor(neg['ISBN'], dtype=torch.long),\n",
        "                    'Book-Title': torch.tensor(neg['Book-Title'], dtype=torch.long),\n",
        "                    'Book-Author': torch.tensor(neg['Book-Author'], dtype=torch.long),\n",
        "                    'Book-Publisher': torch.tensor(neg['Publisher'], dtype=torch.long),\n",
        "                    'Book-Year-Of-Publication': torch.tensor(neg['Year-Of-Publication'], dtype=torch.float32),\n",
        "                }\n",
        "                for neg in negative_examples\n",
        "            ]\n",
        "        }\n",
        "        return output\n",
        "\n",
        "\n",
        "dataset = BookRecommenderDataset(df, negative_examples=10)\n"
      ],
      "metadata": {
        "id": "hzV4YkTNPSuc"
      },
      "execution_count": 266,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lNCVwwNWwUc7",
        "outputId": "8ab1e53f-7cc6-41bc-e600-9a79d9134290"
      },
      "execution_count": 267,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'User-ID': tensor(1),\n",
              " 'User-Age': tensor(0.1068),\n",
              " 'Rating': tensor(6.),\n",
              " 'pos_item': {'Book-ISBN': tensor(1),\n",
              "  'Book-Title': tensor(1),\n",
              "  'Book-Author': tensor(1),\n",
              "  'Book-Publisher': tensor(1),\n",
              "  'Book-Year-Of-Publication': tensor(0.6288)},\n",
              " 'neg_items': [{'Book-ISBN': tensor(297),\n",
              "   'Book-Title': tensor(88),\n",
              "   'Book-Author': tensor(29),\n",
              "   'Book-Publisher': tensor(104),\n",
              "   'Book-Year-Of-Publication': tensor(0.7535)},\n",
              "  {'Book-ISBN': tensor(675),\n",
              "   'Book-Title': tensor(443),\n",
              "   'Book-Author': tensor(91),\n",
              "   'Book-Publisher': tensor(2),\n",
              "   'Book-Year-Of-Publication': tensor(0.1297)},\n",
              "  {'Book-ISBN': tensor(774),\n",
              "   'Book-Title': tensor(179),\n",
              "   'Book-Author': tensor(127),\n",
              "   'Book-Publisher': tensor(12),\n",
              "   'Book-Year-Of-Publication': tensor(0.6288)},\n",
              "  {'Book-ISBN': tensor(688),\n",
              "   'Book-Title': tensor(391),\n",
              "   'Book-Author': tensor(346),\n",
              "   'Book-Publisher': tensor(7),\n",
              "   'Book-Year-Of-Publication': tensor(1.0031)},\n",
              "  {'Book-ISBN': tensor(228),\n",
              "   'Book-Title': tensor(190),\n",
              "   'Book-Author': tensor(35),\n",
              "   'Book-Publisher': tensor(29),\n",
              "   'Book-Year-Of-Publication': tensor(0.0049)},\n",
              "  {'Book-ISBN': tensor(472),\n",
              "   'Book-Title': tensor(342),\n",
              "   'Book-Author': tensor(254),\n",
              "   'Book-Publisher': tensor(3),\n",
              "   'Book-Year-Of-Publication': tensor(-0.1198)},\n",
              "  {'Book-ISBN': tensor(83),\n",
              "   'Book-Title': tensor(80),\n",
              "   'Book-Author': tensor(63),\n",
              "   'Book-Publisher': tensor(47),\n",
              "   'Book-Year-Of-Publication': tensor(0.7535)},\n",
              "  {'Book-ISBN': tensor(315),\n",
              "   'Book-Title': tensor(250),\n",
              "   'Book-Author': tensor(179),\n",
              "   'Book-Publisher': tensor(2),\n",
              "   'Book-Year-Of-Publication': tensor(-4.1124)},\n",
              "  {'Book-ISBN': tensor(159),\n",
              "   'Book-Title': tensor(140),\n",
              "   'Book-Author': tensor(19),\n",
              "   'Book-Publisher': tensor(63),\n",
              "   'Book-Year-Of-Publication': tensor(0.7535)},\n",
              "  {'Book-ISBN': tensor(865),\n",
              "   'Book-Title': tensor(527),\n",
              "   'Book-Author': tensor(420),\n",
              "   'Book-Publisher': tensor(1),\n",
              "   'Book-Year-Of-Publication': tensor(-2.1161)}]}"
            ]
          },
          "metadata": {},
          "execution_count": 267
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_size = int(0.8 * len(dataset))\n",
        "test_size = len(dataset) - train_size\n",
        "train_data, test_data = random_split(dataset, [train_size, test_size])\n",
        "\n",
        "# Dataloaders\n",
        "train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_data, batch_size=64, shuffle=False)"
      ],
      "metadata": {
        "id": "5UuengF0Tojk"
      },
      "execution_count": 268,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "next(iter(train_loader))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vznGD0IGTxA7",
        "outputId": "2b2d6fdb-f25e-40fc-b444-9d1218f410aa"
      },
      "execution_count": 269,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'User-ID': tensor([ 225, 1750, 1293,  807,  609,  946,  880, 2272, 1257,  444, 1839, 1052,\n",
              "         1804, 1578, 2745,  233, 1753,  214, 1932,  348,  576,  378, 1836,  822,\n",
              "         1343,  169, 2262,  180,  438, 1188, 1009,  639,  743, 1559, 2101,  556,\n",
              "         2307,  483,  680,   94,  729, 2687, 2430, 1262,  181,  396, 2159, 2411,\n",
              "         2576, 2338,   81,  739,  464, 1094, 1406, 2711, 2020,  972,  455,  901,\n",
              "          748, 1711,  562,  991]),\n",
              " 'User-Age': tensor([ 0.6807, -1.2870,  0.0248, -0.6311, -0.3031, -0.3031,  1.5006,  0.2708,\n",
              "         -0.7951,  1.3366, -0.7951,  0.0248, -0.7131,  0.3528,  2.8124,  0.0248,\n",
              "         -0.2211, -0.9590, -0.9590,  0.7627,  0.8447, -0.2211, -0.3031, -0.3031,\n",
              "         -0.3851,  0.1888, -0.8771,  0.8447,  0.4348,  0.3528,  1.2546, -0.3031,\n",
              "          0.7627,  1.1727,  0.1888, -0.7131, -0.6311, -0.3851, -1.0410, -0.1392,\n",
              "         -1.0410, -0.5491,  2.4845, -0.9590, -0.4671,  0.4348,  0.6807, -0.3851,\n",
              "         -1.0410,  0.8447,  2.3205, -1.1230, -0.7131,  0.1888, -1.4510, -0.3031,\n",
              "         -0.7131,  0.5987,  1.5826, -1.3690, -1.0410,  1.5006,  0.1888,  1.1727]),\n",
              " 'Rating': tensor([ 5.,  9.,  5.,  7., 10.,  5.,  9.,  8.,  3.,  7.,  7.,  7.,  7., 10.,\n",
              "         10.,  7.,  9.,  6., 10.,  8.,  5.,  5., 10., 10., 10., 10.,  6.,  9.,\n",
              "         10.,  7.,  9.,  5.,  9., 10., 10.,  7.,  8.,  7.,  7.,  4., 10., 10.,\n",
              "          8.,  8., 10., 10.,  7.,  8.,  6.,  8.,  9.,  8.,  9.,  9., 10.,  7.,\n",
              "          8.,  8.,  8.,  7.,  9., 10.,  7., 10.]),\n",
              " 'pos_item': {'Book-ISBN': tensor([1253,   46,  813,  555,  526,  550,  595,  611,  296,  341,  510,  696,\n",
              "           219,  365,  636,   23,   18,  177,  127,  635,   86, 1137, 1069,   83,\n",
              "           847,   66,   79,   17,  336,  144,  676,  823,  519,  248,    4,    4,\n",
              "          1254,  216,  194,  197,  510,  128, 1320,  797, 1359,  310, 1180,  820,\n",
              "           590,  457,   74,  367,   23,  718,   46,  212,  550,  155,  348,  611,\n",
              "           262,  278, 1436,  523]),\n",
              "  'Book-Title': tensor([667,  44, 506, 385, 375,  16, 404, 318,  44, 268,  81,   4, 182, 281,\n",
              "          423,  22,  18, 153, 118, 183,  82, 630, 606,  80, 520,  64,  76,  17,\n",
              "          266, 131, 444, 207, 196, 203,   4,   4, 668, 181, 157, 170,  81, 119,\n",
              "          456, 497, 696, 246, 198, 112, 401, 335,  71, 282,  22, 195,  44, 141,\n",
              "           16,  79, 273, 318,  15, 224, 713,   7]),\n",
              "  'Book-Author': tensor([ 99,  36, 314, 288,  53,  15, 272, 231,  36, 175,  64,   4, 129,  73,\n",
              "          324,  11,  17,   4,  63,  78,  19, 211,   2,  63, 414,  53,  60,  16,\n",
              "          190,  94, 340, 155, 137,  43,   4,   4, 575,   7, 112, 118,  64,  37,\n",
              "          352, 394, 511, 175, 543,  33,  78, 247,  31, 201,  11,   4,  36, 125,\n",
              "           15,  31, 193, 231,  56, 127, 642,   7]),\n",
              "  'Book-Publisher': tensor([  7,  34, 161, 170,   1, 168, 176, 127, 103, 118,  17, 142,  35, 127,\n",
              "           91,  19,  14,   2,  63, 189,   3, 105, 122,  47,   2,   1,  45,   2,\n",
              "            2,  25, 155, 221,  68,  94,   4,   4, 103,   7,  25,  76,  17,  35,\n",
              "           50,   1,  45, 110,  95,  14,   3, 147,  31,  28,  19, 106,  34,  25,\n",
              "          168,   7,  96, 127,  25,  11,  52,   7]),\n",
              "  'Book-Year-Of-Publication': tensor([-0.3694,  0.3792, -1.2428,  0.0049, -0.7437,  0.7535, -2.6152, -1.7418,\n",
              "          -0.7437,  0.3792, -0.7437,  0.6288, -0.9932, -1.4923,  0.8783, -0.3694,\n",
              "           1.0031,  0.7535,  1.0031,  0.5040,  0.5040, -0.2446,  0.1297,  0.7535,\n",
              "          -3.7381,  0.1297,  1.0031, -0.6189,  1.0031,  0.3792, -1.1180, -1.8666,\n",
              "          -0.2446, -0.3694,  0.6288,  0.6288, -0.6189,  0.8783,  0.0049, -0.1198,\n",
              "          -0.7437, -1.1180,  0.7535, -1.9914,  0.6288, -1.7418, -1.3675,  0.8783,\n",
              "          -0.7437, -1.1180,  0.5040,  0.5040, -0.3694,  0.5040,  0.3792,  0.7535,\n",
              "           0.7535,  1.0031, -0.7437, -1.7418,  0.6288,  0.0049, -0.3694,  0.1297])},\n",
              " 'neg_items': [{'Book-ISBN': tensor([  15,   15,  447,  689,  834,   40,   40,   61,  849,  696,   72,  452,\n",
              "            424,  127,  210,  390,  550, 1355,  595,   50,  440,   33,  352, 1114,\n",
              "            461,  888,  187,  189,  208,  147,  519,  208,  194,   46,  157,  127,\n",
              "            256,  811, 1296,   52, 1290,  264,   45,  730,  155,  194, 1313, 1287,\n",
              "             54, 1276,  170,  233,  367,  528,  174,    9, 1029,  526, 1149,  402,\n",
              "            107,  641,   76, 1018]),\n",
              "   'Book-Title': tensor([ 15,  15, 193, 450, 512,  39,  39,  59, 263,   4,  69, 307, 317, 118,\n",
              "           115,  51,  16, 323, 404,  48, 116,  32, 223, 474, 338, 229,  97,  73,\n",
              "           178, 133, 196, 178, 157,  44,  77, 118, 208, 505, 682,  50, 679, 215,\n",
              "            43, 199,  79, 157, 454, 675,  52, 522, 147,  96, 282, 186, 151,   9,\n",
              "           238, 375, 635, 306, 102, 321,  73, 256]),\n",
              "   'Book-Author': tensor([ 14,  14, 135,  91, 408,   7,   7,  50, 189,   4,  56, 208, 230,  63,\n",
              "            85,  19,  15, 208, 272,  40, 238,  26,  13, 524, 250, 162,  29,  59,\n",
              "           124,  96, 137, 124, 112,  36,  43,  63,  11, 402, 595,  42, 591,   3,\n",
              "            35, 366,  31, 112, 253, 589,  26, 585, 106,  29, 201, 277, 108,   9,\n",
              "           483,  53, 535,  53,  19, 122,  59, 184]),\n",
              "   'Book-Publisher': tensor([ 13,  13,  29, 123,  62,   7,   7,  42,  91, 142,  25,  58, 140,  63,\n",
              "            62,  63, 168,  30, 176,  33,  56,  26,   1, 190,  17, 232,  55,  14,\n",
              "            80,  69,  68,  80,  25,  34,   4,  63,  19,  78, 311,  37, 170,   4,\n",
              "            29,  25,   7,  25,  33,  92,  26, 261,   3,  60,  28, 100,  25,   9,\n",
              "           103,   1,  29,   1,   3,  46,  44,   7]),\n",
              "   'Book-Year-Of-Publication': tensor([ 0.5040,  0.5040,  0.5040,  0.1297, -0.6189,  0.6288,  0.6288,  0.0049,\n",
              "           -1.7418,  0.6288, -0.8685,  0.5040,  0.2545,  1.0031, -2.3657,  0.7535,\n",
              "            0.7535, -1.4923, -2.6152,  1.0031,  0.7535,  0.6288,  0.3792,  0.5040,\n",
              "            0.2545,  0.5040, -1.7418,  0.6288, -0.8685,  0.8783, -0.2446, -0.8685,\n",
              "            0.0049,  0.3792,  0.0049,  1.0031,  0.1297, -0.7437, -0.7437, -2.3657,\n",
              "            0.1297,  0.7535,  1.0031,  0.2545,  1.0031,  0.0049,  0.1297,  0.6288,\n",
              "            0.8783,  0.2545,  0.3792,  1.1278,  0.5040,  0.7535,  0.8783, -1.2428,\n",
              "           -0.3694, -0.7437, -1.7418,  0.2545,  0.1297, -0.7437,  0.6288,  0.6288])},\n",
              "  {'Book-ISBN': tensor([ 127,   14, 1037,  275,  211, 1286,   88,  173,  189,  424, 1353,  262,\n",
              "           1181,   33, 1123,    1,  298, 1102,   76,   21,  511,  338,   17,  362,\n",
              "            560,  196,  703, 1437, 1047,  402,  708,  527,  622,  805,   72, 1314,\n",
              "            500,  201,   80,  958,  423, 1293,  730,  321,  478,  976,  157,   14,\n",
              "            129,  553,  601, 1430,  160,  982,   83,  167,   17,   31,   60, 1340,\n",
              "            930,  764,  521,  211]),\n",
              "   'Book-Title': tensor([118,  14, 594, 222, 148, 294,  84, 150,  73, 317, 190,  15, 643,  32,\n",
              "           624,   1, 238, 280,  73,  21, 368,  73,  17,  12, 317, 169, 330, 605,\n",
              "           147, 306,  15, 146, 325, 417,  69, 205,   5, 173,  77, 291, 186, 462,\n",
              "           199,  92, 345, 198,  77,  14, 120, 377, 259, 636, 127,  16,  80,  75,\n",
              "            17,  30,  58, 178,  84, 481, 373, 148]),\n",
              "   'Book-Author': tensor([ 63,  13, 485, 156,  13, 119,  29, 107,  59, 230, 611,  56, 544,  26,\n",
              "           527,   1, 169, 200,  59,   2, 272,  59,  16,  11, 230,  53,  29, 500,\n",
              "           106,  53,  14, 105, 316,  57,  56,  29, 123,  26,  43, 454,  30, 594,\n",
              "           366,  71, 256,  29,  43,  13,  87,  30, 143, 639,   7,  15,  63,  43,\n",
              "            16,  14,  49, 124,  29, 379, 276,  13]),\n",
              "   'Book-Publisher': tensor([ 63,   1,  31,   2,  82,  77,   2,  22,  14, 140, 316,  25, 177,  26,\n",
              "            11,   1, 105, 212,  44,  17, 162,  14,   2,  25,  10,  17,  46,  13,\n",
              "            54,   1, 205,  29, 174,   1,  25,  95, 159,  26,  46,  25,  92,  19,\n",
              "            25,  56,  11, 248,   4,   1,  64,  29,  13,   2,   7, 250,  47,  73,\n",
              "             2,  25,  41, 101,  55, 111,  36,  82]),\n",
              "   'Book-Year-Of-Publication': tensor([ 1.0031,  0.5040,  0.5040, -1.3675,  0.1297,  0.8783,  1.1278, -0.4942,\n",
              "            0.6288,  0.2545,  0.6288,  0.6288,  1.0031,  0.6288,  0.8783,  0.6288,\n",
              "            1.0031,  1.0031,  0.6288, -1.7418, -0.8685,  0.6288, -0.6189,  0.8783,\n",
              "            0.3792,  0.6288, -0.2446, -2.7400,  0.1297,  0.2545,  0.8783, -0.6189,\n",
              "           -0.7437,  0.3792, -0.8685, -1.8666,  1.0031, -0.3694, -0.1198, -1.9914,\n",
              "            0.7535,  0.7535,  0.2545,  0.2545,  0.7535, -1.2428,  0.0049,  0.5040,\n",
              "            0.1297, -0.3694,  0.6288, -0.1198,  1.0031,  0.7535,  0.7535,  0.5040,\n",
              "           -0.6189,  0.5040,  1.0031,  0.0049,  0.0049,  0.2545, -0.1198,  0.1297])},\n",
              "  {'Book-ISBN': tensor([  18,  487,   11,  373,  189,   88,  418, 1022,  573,  281,  140,  561,\n",
              "            964,  127,  307,   48,   74,  211,  155,  895,  453, 1231,  248,  630,\n",
              "            578,   38,  885,  248,  248,  146, 1002,  112,  269,   95,   20, 1187,\n",
              "            386,  203,  319,    7, 1169, 1139, 1031,  369,  149,  737,   23,   72,\n",
              "            237,  735,  407,  406,  111,  268, 1276,   72,  234,  148,  912, 1239,\n",
              "           1188,  263,   18,  175]),\n",
              "   'Book-Title': tensor([ 18, 353,  11,  38,  73,  84, 314, 589, 271, 202, 127, 231, 137, 118,\n",
              "           244,  46,  71, 148,  79, 541, 332, 493, 203, 210, 332,  37, 540, 203,\n",
              "           203, 132, 539, 107, 217,  91,  20, 646, 195,  79, 144,   7, 462, 309,\n",
              "           182, 284,  53,  16,  22,  69, 197, 460, 309, 308, 106,  63, 522,  69,\n",
              "           195,  56, 351, 591, 262, 214,  18,  60]),\n",
              "   'Book-Author': tensor([ 17, 259,  10,  31,  59,  29, 227, 155,  29,  47,  30,  29, 458,  63,\n",
              "           174,  38,  31,  13,  31, 240, 243, 391,  43, 320,  13,  29, 430,  43,\n",
              "            43,  95, 429,  80, 151,  70,  18, 548,   4,  31, 181,   7, 108,  44,\n",
              "           229, 203,  44,  15,  11,  56, 138, 357,  44, 220,  79,   8, 585,  56,\n",
              "             4,  47,  27, 482, 188,  70,  17,  19]),\n",
              "   'Book-Publisher': tensor([ 14,  25,  11, 128,  14,   2, 139, 100,   2,  35,  65,  18, 245,  63,\n",
              "           108,  17,  31,  82,   7,  29,   1,  22,  94, 185,  12,  30,   2,  94,\n",
              "            94,  68, 252,  60,  17,  36,  16, 285,   4,   6, 111,   7,   2,  70,\n",
              "           257,  33,  70,  55,  19,  25,  90, 117,  38, 118,  17,  18, 261,  25,\n",
              "            89,  35,  25,  70,  14,  74,  14,  63]),\n",
              "   'Book-Year-Of-Publication': tensor([ 1.0031,  0.2545,  0.6288,  0.6288,  0.6288,  1.1278, -0.8685, -0.2446,\n",
              "           -0.1198,  0.3792,  0.1297, -0.7437,  0.6288,  1.0031, -0.2446, -1.6171,\n",
              "            0.5040,  0.1297,  1.0031,  0.8783,  0.8783, -0.6189, -0.3694,  0.8783,\n",
              "            0.7535, -1.4923, -0.4942, -0.3694, -0.3694, -0.6189, -0.6189,  0.6288,\n",
              "           -1.3675,  0.3792,  0.8783,  0.3792,  0.6288,  0.8783,  0.1297,  0.3792,\n",
              "           -0.2446,  0.6288, -0.1198,  1.0031,  0.6288,  0.3792, -0.3694, -0.8685,\n",
              "            1.0031,  0.7535,  0.5040,  0.8783, -1.9914, -0.9932,  0.2545, -0.8685,\n",
              "            0.5040,  0.2545,  0.6288, -0.1198,  0.7535,  1.0031,  1.0031,  0.6288])},\n",
              "  {'Book-ISBN': tensor([ 347,  428,   70,  517,  127,  248,  138,  321, 1170, 1140,   48,    6,\n",
              "             61, 1460,   39,  785,  316, 1207,  901, 1088,   27, 1012,  137,  249,\n",
              "           1127,   50,  217,  102,  205,  127,  475,  167,  127,  251, 1189,  159,\n",
              "            658,  281,  595, 1299,   47, 1041,  648,  614, 1447,  222,  140,    7,\n",
              "           1437,  219,  269,  296,   87,   64,  127,  189,  248,  599,   48,  352,\n",
              "            127, 1347,  787,  791]),\n",
              "   'Book-Title': tensor([272, 320,  35,  67, 118, 203, 125,  92, 162, 104,  46,   6,  59, 718,\n",
              "            38, 491, 251, 171, 546, 384,  26, 396,  54, 203, 298,  48,  83,  97,\n",
              "           176, 118, 129,  75, 118, 205, 647, 140, 434, 202, 404, 683,  45, 597,\n",
              "            13, 412, 189, 185, 127,   7, 605, 182, 217,  44,  83,  62, 118,  73,\n",
              "           203, 406,  46, 223, 118, 692, 214, 493]),\n",
              "   'Book-Author': tensor([ 51, 233,  29,  29,  63,  43,  91,  71, 115,  78,  38,   6,  50, 394,\n",
              "            31, 389,  29, 119, 253, 287,  22,  33,  45,  43, 529,  40,  29,  29,\n",
              "           116,  63,  93,  43,  63,  29, 549,  19, 333,  47, 272, 596,  37, 489,\n",
              "            12, 313,  57, 131,  30,   7, 500, 129, 151,  36,  29,  52,  63,  59,\n",
              "            43, 305,  38,  13,  63, 106,  70, 391]),\n",
              "   'Book-Publisher': tensor([ 25,  17,  29,   2,  63,  94,   2,  56,  95, 142,  17,   6,  42,  30,\n",
              "            31, 138,   2, 291,  33,   2,  22,  14,   7,  46,  78,  33,   2,   2,\n",
              "            26,  63,  91,  73,  63,   2,   7,  63, 197,  35, 176,  87,  35, 260,\n",
              "           190,  36,  30,  86,  65,   7,  13,  35,  17, 103,   2,   3,  63,  14,\n",
              "            94, 139,  17,   1,  63,   3,  66,  25]),\n",
              "   'Book-Year-Of-Publication': tensor([ 0.1297,  0.6288,  0.7535,  0.3792,  1.0031, -0.3694,  0.1297,  0.2545,\n",
              "           -1.9914,  0.7535, -1.6171, -0.4942,  0.0049, -2.1161,  0.7535, -0.2446,\n",
              "            0.7535,  0.7535, -0.2446, -1.7418, -0.8685,  0.8783, -0.3694, -0.4942,\n",
              "            0.2545,  1.0031,  1.0031,  1.1278, -0.2446,  1.0031, -3.3638,  0.5040,\n",
              "            1.0031,  1.1278,  1.1278,  0.7535, -0.4942,  0.3792, -2.6152, -0.8685,\n",
              "           -1.1180,  0.7535, -1.1180,  0.2545, -0.1198, -0.2446,  0.1297,  0.3792,\n",
              "           -2.7400, -0.9932, -1.3675, -0.7437, -1.3675, -0.1198,  1.0031,  0.6288,\n",
              "           -0.3694, -1.3675, -1.6171,  0.3792,  1.0031, -0.4942,  0.8783, -1.7418])},\n",
              "  {'Book-ISBN': tensor([ 333,  160,  440,   83,  291,  396,  148,  135,  934,  390,  148,  139,\n",
              "            358,  293, 1039,   76,  863,  147,   57,  814,  248, 1412,  190,    7,\n",
              "            155,  726,  814,    4,  527,  819,   78,  127,  290,  642,  208,  484,\n",
              "            406, 1058,  329,  512,  707,  937,  673, 1098,  233,   32,  855,  133,\n",
              "           1374,   12,   23,   52,   12,   95,  561,    6,   50,  422,  959,  518,\n",
              "             72,  923,  390,   83]),\n",
              "   'Book-Title': tensor([263, 127, 116,  80, 234, 228,  56, 124, 405,  51,  56, 126,  82, 236,\n",
              "           596,  73, 518, 133,  55,  64, 203, 207, 164,   7,  79, 467,  64,   4,\n",
              "           146, 134,  75, 118, 233, 311, 178, 350, 308, 525, 259, 369, 304, 557,\n",
              "           345, 157,  96,  31, 522, 122,  62,  12,  22,  50,  12,  91, 231,   6,\n",
              "            48,  80, 239, 371,  69, 553,  51,  80]),\n",
              "   'Book-Author': tensor([189,   7, 238,  63,  29,  52,  47,  89,  53,  19,  47,  29,  43, 167,\n",
              "           487,  59, 412,  96,  46, 215,  43, 155,  19,   7,  31, 364, 215,   4,\n",
              "           105,  97,  43,  63, 165, 222, 124, 258, 220, 418,  47, 273,   1,   3,\n",
              "           256, 112,  29,  25, 416,  88,  52,  11,  11,  42,  11,  70,  29,   6,\n",
              "            40,  63, 169,  26,  56, 211,  19,  63]),\n",
              "   'Book-Publisher': tensor([116,   7,  56,  47,  55, 106,  35,  55,   1,  63,  35,   2,  46,  33,\n",
              "           259,  44,  74,  69,   3, 219,  94, 325,   3,   7,   7, 138, 219,   4,\n",
              "            29, 220,   3,  63,  20, 142,  80,  58, 118,  30, 115, 163,  96,   3,\n",
              "            12,  29,  60,   2, 225,  45, 106,  12,  19,  37,  12,  36,  18,   6,\n",
              "            33,  92,  12,  26,  25,   7,  63,  47]),\n",
              "   'Book-Year-Of-Publication': tensor([ 0.5040,  1.0031,  0.7535,  0.7535,  1.0031, -0.1198,  0.2545,  0.6288,\n",
              "            0.8783,  0.7535,  0.2545,  0.2545,  0.3792,  0.6288,  0.7535,  0.6288,\n",
              "           -2.8647,  0.8783, -0.3694,  1.0031, -0.3694, -1.2428, -0.3694,  0.3792,\n",
              "            1.0031, -1.8666,  1.0031,  0.6288, -0.6189,  0.2545,  0.5040,  1.0031,\n",
              "           -2.9895,  0.7535, -0.8685, -0.9932,  0.8783, -1.3675,  1.0031, -1.8666,\n",
              "           -0.4942, -0.2446,  0.6288, -0.4942,  1.1278,  0.1297, -0.6189,  0.1297,\n",
              "           -0.2446,  0.7535, -0.3694, -2.3657,  0.7535,  0.3792, -0.7437, -0.4942,\n",
              "            1.0031,  1.0031,  0.8783,  0.8783, -0.8685,  0.8783,  0.7535,  0.7535])},\n",
              "  {'Book-ISBN': tensor([ 193,   95,    5,  424,   31,   17,   24,  480,  333,  358,  757,   11,\n",
              "            752,  832,  570,  623,  221,  208,  638,  264,  338,   83,   39,  376,\n",
              "            127,   63,  510,  248, 1314,  194,  886, 1025,   18, 1337,   75,    3,\n",
              "            759,   34,   17,  331,  126,   61,  509, 1248,  723,  470,  239,  766,\n",
              "            778,  157,  248, 1064,   39,  643,  476,  194,  262,  262,  523,   75,\n",
              "             85,   23,  316,  113]),\n",
              "   'Book-Title': tensor([167,  91,   5, 317,  30,  17,  23, 347, 263,  82, 238,  11, 476, 407,\n",
              "           307, 415, 184, 178,  58, 215,  73,  80,  38,  42, 118,  61,  81, 203,\n",
              "           205, 157, 407, 135,  18, 342,  72,   3,  61,  33,  17, 261, 106,  59,\n",
              "           330, 663, 289,  82, 173, 315,  87,  77, 203, 126,  38, 424,  16, 157,\n",
              "            15,  15,   7,  72,  74,  22, 251,  85]),\n",
              "   'Book-Author': tensor([117,  70,   5, 230,  14,  16,  19,  70, 189,  43, 249,  10, 374,  90,\n",
              "           208, 317, 130, 124,  49,   3,  59,  63,  31,  34,  63,  51,  64,  43,\n",
              "            29, 112, 431,  33,  17,  53,  58,   3,  51,  27,  16,  85,   7,  50,\n",
              "            29, 571,  29,  43, 139, 228,  67,  43,  43,  29,  31, 282,  15, 112,\n",
              "            56,  56,   7,  58,   7,  11,  29,  37]),\n",
              "   'Book-Publisher': tensor([  7,  36,   5, 140,  25,   2,   3, 152, 116,  46,  92,  11, 177,  29,\n",
              "             1,  30,  74,  80, 191,   4,  14,  47,  31,  12,  63,   1,  17,  94,\n",
              "            95,  25, 230, 110,  14,   1,  26,   3,  27,  27,   2,  62,   7,  42,\n",
              "             2,  25,  18, 149,  92, 214,  29,   4,  94,  29,  31, 134, 151,  25,\n",
              "            25,  25,   7,  26,  31,  19,   2,  35]),\n",
              "   'Book-Year-Of-Publication': tensor([ 1.0031,  0.3792, -4.4867,  0.2545,  0.5040, -0.6189,  0.2545,  0.5040,\n",
              "            0.5040,  0.3792,  0.6288,  0.6288,  0.1297, -1.2428, -1.3675, -1.8666,\n",
              "           -0.9932, -0.8685,  0.8783,  0.7535,  0.6288,  0.7535,  0.7535,  1.0031,\n",
              "            1.0031, -0.1198, -0.7437, -0.3694, -1.8666,  0.0049, -0.7437, -1.4923,\n",
              "            1.0031,  0.7535, -1.2428,  0.2545, -0.8685,  0.6288, -0.6189, -0.6189,\n",
              "            1.0031,  0.0049, -1.3675, -0.8685,  1.0031,  0.5040,  0.7535, -0.1198,\n",
              "           -0.9932,  0.0049, -0.3694,  0.7535,  0.7535, -0.8685,  0.2545,  0.0049,\n",
              "            0.6288,  0.6288,  0.1297, -1.2428,  0.5040, -0.3694,  0.7535, -1.2428])},\n",
              "  {'Book-ISBN': tensor([ 127, 1022,  435, 1083,  755,  296,   18,  775, 1055,   83, 1084,  109,\n",
              "           1375,   76,  668, 1073,  912,  646,  271,  159,   70,  386,   22, 1105,\n",
              "            125,  104,  148,  263,  219,  281,  233,   47, 1157,   49, 1304,  672,\n",
              "            338, 1387, 1249,  339,    7, 1457,  930, 1066,  404,  734,   56,  628,\n",
              "             53,  127,  721,   89,  803,   18,  423,  829,  187,  163,  155,  511,\n",
              "              7,  490,  478,   19]),\n",
              "   'Book-Title': tensor([118, 589, 234, 611, 198,  44,  18, 476, 603,  80, 110, 104, 247,  73,\n",
              "           263, 608, 351, 427,  39, 140,  35, 195,   8,  94, 117,  99,  56, 214,\n",
              "           182, 202,  96,  45, 623,  47, 683, 442,  73, 698, 664, 267,   7, 598,\n",
              "            84, 604,  91, 469,  54, 418,  51, 118, 464,  85, 345,  18, 186, 488,\n",
              "            97, 143,  79, 368,   7,  96, 345,  19]),\n",
              "   'Book-Author': tensor([ 63, 155,  29, 509,  29,  36,  17, 374, 497,  63,  29,  78,  80,  59,\n",
              "           189, 505,  27,  53,   7,  19,  29,   4,   8, 491,  14,  74,  47,  70,\n",
              "           129,  47,  29,  37, 526,  39, 597, 106,  59, 621, 572, 191,   7, 490,\n",
              "            29, 499,  70,  52,  45, 319,  43,  63, 361,  65, 396,  17,  30, 406,\n",
              "            29,  26,  31, 272,   7,  29, 256,  14]),\n",
              "   'Book-Publisher': tensor([ 63, 100, 123, 270,  95, 103,  14,  46,   1,  47, 253,   2,  13,  44,\n",
              "            67, 118,  25,   1,   7,  63,  29,   4,  18, 161,  25,  56,  35,  74,\n",
              "            35,  35,  60,  35,  41,   2,   9,  33,  14,  34, 110,   7,   7, 224,\n",
              "            55,  30,  88,   3,   7, 161,   4,  63,  75,  49,   7,  14,  92, 143,\n",
              "            55,  26,   7, 162,   7,  81,  11,  15]),\n",
              "   'Book-Year-Of-Publication': tensor([ 1.0031, -0.2446, -0.1198, -0.8685, -1.2428, -0.7437,  1.0031, -1.4923,\n",
              "            0.0049,  0.7535,  0.5040,  0.8783, -3.8629,  0.6288, -0.7437,  0.3792,\n",
              "            0.6288, -0.3694,  0.7535,  0.7535,  0.7535,  0.6288,  0.3792, -0.4942,\n",
              "            0.2545,  0.8783,  0.2545,  1.0031, -0.9932,  0.3792,  1.1278, -1.1180,\n",
              "           -0.6189,  0.1297, -0.3694,  0.8783,  0.6288, -0.9932, -1.7418,  0.7535,\n",
              "            0.3792,  0.0049,  0.0049, -1.2428,  0.3792, -0.8685,  0.0049, -0.1198,\n",
              "            0.7535,  1.0031,  1.0031,  0.7535,  0.5040,  1.0031,  0.7535,  0.3792,\n",
              "           -1.7418, -0.2446,  1.0031, -0.8685,  0.3792,  0.5040,  0.7535,  1.0031])},\n",
              "  {'Book-ISBN': tensor([  83,  297,  118,  944,  175,  478,  533,  190,  167,   24, 1240,   31,\n",
              "             72,  250,  110,  131,  988,  695,  409,  330,  870,  328,  127,  307,\n",
              "            934,   86,  171,  812, 1061,  137, 1161,  458,  389,   89,  678,  481,\n",
              "            150,  159,  190,  557, 1370,  604,  247,  127, 1251,  421,  166,   17,\n",
              "            695,  362,  354,  445, 1168,  638,   83,  374,   37,  234,  489,  176,\n",
              "            191, 1413,  848,  606]),\n",
              "   'Book-Title': tensor([ 80,  88, 111, 511,  60, 345, 315, 164,  75,  23, 658,  30,  69, 204,\n",
              "           105, 121, 575, 308, 181, 260, 531, 258, 118, 244, 405,  82, 148, 397,\n",
              "           491,  54, 492,  52, 123,  85, 446, 200,  74, 140, 164, 387, 152, 407,\n",
              "           202, 118, 580, 316, 145,  17, 308,  12, 275,  14, 640,  58,  80, 287,\n",
              "            36, 195, 333, 152, 165, 647, 148,  92]),\n",
              "   'Book-Author': tensor([ 63,  29,  29, 405,  19, 256, 228,  19,  43,  19, 398,  14,  56,  14,\n",
              "            16,  13, 470, 220,   7, 187, 108, 186,  63, 174,  53,  19,  13,  46,\n",
              "           389,  45, 155,  26, 213,  65, 342, 140,   7,  19,  19, 290, 214, 307,\n",
              "           143,  63,  57, 229, 104,  16, 220,  11, 195,  13, 539,  49,  63, 205,\n",
              "            30,   4, 261, 109,  29, 631, 415, 309]),\n",
              "   'Book-Publisher': tensor([ 47, 104,   2,  25,  63,  11,   2,   3,  73,   3,  87,  25,  25,  25,\n",
              "            59,   1,   2,  75,   7,   1,   2, 114,  63, 108,   1,   3,   1,   3,\n",
              "           264,   7, 100,  26,  62,  49,  11,  11,   7,  63,   3, 167,  74, 179,\n",
              "            93,  63,  30,  17,  26,   2,  75,  25, 122,  82,  42, 191,  47, 129,\n",
              "            29,  89,  17,  21,   2, 105,  46,  27]),\n",
              "   'Book-Year-Of-Publication': tensor([ 0.7535,  0.7535, -0.1198, -1.6171,  0.6288,  0.7535, -4.4867, -0.3694,\n",
              "            0.5040,  0.2545,  0.1297,  0.5040, -0.8685,  0.1297,  1.1278,  0.6288,\n",
              "           -0.2446,  1.0031,  0.7535,  0.2545, -0.9932,  0.7535,  1.0031, -0.2446,\n",
              "            0.8783,  0.5040,  0.2545, -0.1198, -0.3694, -0.3694, -0.2446,  1.1278,\n",
              "           -0.6189,  0.7535, -0.6189,  0.1297,  0.3792,  0.7535, -0.3694,  0.7535,\n",
              "            0.3792,  1.1278,  0.3792,  1.0031, -1.3675, -1.3675, -0.6189, -0.6189,\n",
              "            1.0031,  0.8783,  0.2545,  0.5040,  0.0049,  0.8783,  0.7535, -1.6171,\n",
              "            0.7535,  0.5040, -1.4923,  0.2545, -0.1198,  1.0031,  0.1297,  0.3792])},\n",
              "  {'Book-ISBN': tensor([1087,  777, 1224,   74,  977,  932, 1224, 1337, 1178, 1034,  624,  406,\n",
              "            102,  203,  106,  219,  274, 1304,  555,  799,   53,   70, 1190,  555,\n",
              "            841, 1288,  216,  323, 1336,   18,  452, 1282,  553,  131,  819,   86,\n",
              "             25,  390,  466,  188,  796,  470,  466, 1359, 1103,  159,   85,   14,\n",
              "             83,  155,  203,  299,  308,   46,    5,   57,  143,  742,  646,  829,\n",
              "            626,  818,   50, 1353]),\n",
              "   'Book-Title': tensor([478, 440, 303,  71, 375,  40, 303, 342,  54, 592, 416, 308,  97,  79,\n",
              "           101, 182, 221, 683, 385, 498,  51,  35, 626, 385, 129, 678, 181, 254,\n",
              "           653,  18, 307, 514, 377, 121, 134,  82,  24,  51, 272, 163,  64,  82,\n",
              "           272, 696, 310, 140,  74,  14,  80,  79,  79, 239, 245,  44,   5,  55,\n",
              "           130, 464, 427, 488,  33, 164,  48, 190]),\n",
              "   'Book-Author': tensor([511, 338, 562,  31, 464,  32, 562,  53,  45, 256, 318, 220,  29,  31,\n",
              "            76, 129, 155, 597, 288, 395,  43,  29, 127, 288,  93, 590,   7,  86,\n",
              "           341,  17, 208, 135,  30,  13,  97,  19,  20,  19, 252, 116, 161,  43,\n",
              "           252, 511, 221,  19,   7,  13,  63,  31,  31, 169,  75,  36,   5,  46,\n",
              "            37, 361,  53, 406,  27,  43,  40, 611]),\n",
              "   'Book-Publisher': tensor([199, 130, 101,  31, 249,  32, 101,   1, 183,   2,   7, 118,   2,   6,\n",
              "            17,  35, 100,   9, 170, 217,   4,  29,  82, 170,  67,   1,   7,  25,\n",
              "            21,  14,  58,  29,  29,   1, 220,   3,  20,  63,  19,  26,   3, 149,\n",
              "            19,  45,  15,  63,  31,   1,  47,   7,   6,  11,  26,  34,   5,   3,\n",
              "            35, 209,   1, 143,  25,  46,  33, 316]),\n",
              "   'Book-Year-Of-Publication': tensor([ 1.0031, -0.7437,  0.5040,  0.5040, -0.2446,  1.0031,  0.5040,  0.7535,\n",
              "            0.0049,  0.7535,  0.8783,  0.8783,  1.1278,  0.8783, -1.4923, -0.9932,\n",
              "           -0.3694, -0.3694,  0.0049, -2.4904,  0.7535,  0.7535, -0.7437,  0.0049,\n",
              "            0.6288,  0.8783,  0.8783, -0.1198,  0.5040,  1.0031,  0.5040, -0.3694,\n",
              "           -0.3694,  0.6288,  0.2545,  0.5040, -1.3675,  0.7535, -0.3694, -0.3694,\n",
              "            0.1297,  0.5040, -0.3694,  0.6288, -3.1143,  0.7535,  0.5040,  0.5040,\n",
              "            0.7535,  1.0031,  0.8783,  1.1278, -0.6189,  0.3792, -4.4867, -0.3694,\n",
              "           -1.1180,  1.0031, -0.3694,  0.3792,  0.7535, -0.2446,  1.0031,  0.6288])},\n",
              "  {'Book-ISBN': tensor([ 150,  148,   17,  817, 1055,  749, 1219,    7,  910,  196, 1176,  194,\n",
              "            390,  792,  713,   61,  195,   88,  262,   72, 1152,  144,   23, 1051,\n",
              "            465,  866,  271, 1039,  194,   62, 1416,  362,   55,  507, 1199, 1325,\n",
              "            175,  521,  219,  461,  165,  168,  732,  533, 1119,  233, 1206,  503,\n",
              "            703, 1210, 1244,   19,  167, 1396, 1062, 1408, 1015,  123,   32,   39,\n",
              "            925, 1050,   47,  195]),\n",
              "   'Book-Title': tensor([ 74,  56,  17, 507, 603, 475, 503,   7, 120, 169, 284, 157,  51, 494,\n",
              "           460,  59, 168,  84,  15,  69, 630, 131,  22,  36,  85, 528,  39, 596,\n",
              "           157,  60, 707,  12,  53, 366, 445,  53,  60, 373, 182, 338, 134, 117,\n",
              "           468, 315,  95,  96, 652, 363, 330, 562, 661,  19,  75, 254, 459, 649,\n",
              "           582, 115,  31,  38, 554, 602,  45, 168]),\n",
              "   'Book-Author': tensor([  7,  47,  16, 403, 497, 372, 400,   7,  87,  53, 203, 112,  19,  75,\n",
              "           357,  50,  52,  29,  56,  56, 536,  94,  11,  30, 119, 421,   7, 487,\n",
              "           112,  43, 633,  11,  44, 271, 341,  44,  19, 276, 129, 250,  97,  14,\n",
              "           233, 228,   3,  29, 554, 108,  29,  51, 568,  14,  43,  86, 370, 629,\n",
              "           366,  85,  25,  31,  44, 495,  37,  52]),\n",
              "   'Book-Publisher': tensor([  7,  35,   2,  39,   1, 174,  41,   7, 237,  17, 132,  25,  63,  22,\n",
              "             2,  42,   3,   2,  25,  25,  45,  25,  19,  92,  77, 226,   7, 259,\n",
              "            25,  43, 327,  25,  38,  26, 287,  82,  63,  36,  35,  17,   3,  13,\n",
              "            17,   2,   4,  60,  21,   2,  46,  19, 118,  15,  73, 322,  27,  17,\n",
              "            25,  62,   2,  31,  70, 262,  35,   3]),\n",
              "   'Book-Year-Of-Publication': tensor([ 0.3792,  0.2545, -0.6189, -2.3657,  0.0049,  1.0031, -0.9932,  0.3792,\n",
              "            0.3792,  0.6288,  0.5040,  0.0049,  0.7535, -0.9932,  1.1278,  0.0049,\n",
              "           -0.3694,  1.1278,  0.6288, -0.8685, -0.1198,  0.3792, -0.3694,  0.6288,\n",
              "           -2.2409, -0.2446,  0.7535,  0.7535,  0.0049,  0.6288,  0.1297,  0.8783,\n",
              "            0.1297, -3.7381, -0.9932,  0.0049,  0.6288, -0.1198, -0.9932,  0.2545,\n",
              "            0.0049,  0.1297,  1.0031, -4.4867,  0.0049,  1.1278,  0.0049, -0.2446,\n",
              "           -0.2446, -0.2446,  0.6288,  1.0031,  0.5040, -1.2428,  0.0049, -0.2446,\n",
              "            0.5040, -0.1198,  0.1297,  0.7535,  0.6288, -0.3694, -1.1180, -0.3694])}]}"
            ]
          },
          "metadata": {},
          "execution_count": 269
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Two Tower Model for Recommendations"
      ],
      "metadata": {
        "id": "qjn33eipT_-e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class UserTower(nn.Module):\n",
        "\n",
        "    # User Tower -- User-ID, Age\n",
        "\n",
        "    def __init__(self, num_users, embedding_dim=16):\n",
        "        super().__init__()\n",
        "        self.user_embedding = nn.Embedding(num_users, embedding_dim, padding_idx=0)\n",
        "\n",
        "        self.user_mlp = nn.Sequential(\n",
        "            nn.Linear(embedding_dim + 1, 64), # 1 embedding + 1 numerical\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(64, embedding_dim),\n",
        "        )\n",
        "\n",
        "    def forward(self, user_id, age):\n",
        "        \"\"\"\n",
        "        user_id: (batch,) int64\n",
        "        review_mean: (batch,) float32\n",
        "        \"\"\"\n",
        "        user_emb = self.user_embedding(user_id)\n",
        "        age = age.unsqueeze(1)\n",
        "        x = torch.cat([user_emb, age], dim=1)\n",
        "        return self.user_mlp(x)\n",
        "\n",
        "    def get_embedding(self, data):\n",
        "        return self.forward(data['User-ID'], data['User-Age'])\n"
      ],
      "metadata": {
        "id": "J4Rh2nDqUCxf"
      },
      "execution_count": 270,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ItemTower(nn.Module):\n",
        "    def __init__(self, num_isbn, num_titles, num_authors, num_publishers, embedding_dim=16):\n",
        "        super().__init__()\n",
        "\n",
        "        # Item Tower -- ISBN, Book-Title, Book-Author, Publisher, Year-Of-Publication\n",
        "\n",
        "        self.book_isbn_embedding = nn.Embedding(num_isbn, embedding_dim, padding_idx=0)\n",
        "        self.book_title_embedding = nn.Embedding(num_titles, embedding_dim, padding_idx=0)\n",
        "        self.book_author_embedding = nn.Embedding(num_authors, embedding_dim, padding_idx=0)\n",
        "        self.book_publisher_embedding = nn.Embedding(num_publishers, embedding_dim, padding_idx=0)\n",
        "\n",
        "        self.item_mlp = nn.Sequential(\n",
        "            nn.Linear(embedding_dim * 4 + 1, 64),  # 4 embeddings + 1 numerical\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(64, embedding_dim),\n",
        "        )\n",
        "\n",
        "    def forward(self, isbn, book_title, book_author, book_publisher, book_year_of_publication):\n",
        "        book_isbn_emb = self.book_isbn_embedding(isbn)\n",
        "        book_title_emb = self.book_title_embedding(book_title)\n",
        "        book_author_emb = self.book_author_embedding(book_author)\n",
        "        book_publisher_emb = self.book_publisher_embedding(book_publisher)\n",
        "        book_year = book_year_of_publication.unsqueeze(1)\n",
        "\n",
        "        x = torch.cat([\n",
        "            book_isbn_emb,\n",
        "            book_title_emb,\n",
        "            book_author_emb,\n",
        "            book_publisher_emb,\n",
        "            book_year\n",
        "        ], dim=1)\n",
        "\n",
        "        return self.item_mlp(x)\n",
        "\n",
        "    def get_embedding(self, data):\n",
        "        return self.forward(\n",
        "            data['Book-ISBN'],\n",
        "            data['Book-Title'],\n",
        "            data['Book-Author'],\n",
        "            data['Book-Publisher'],\n",
        "            data['Book-Year-Of-Publication'],\n",
        "        )\n"
      ],
      "metadata": {
        "id": "hLSZeUSEUNBY"
      },
      "execution_count": 271,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TwoTowers(nn.Module):\n",
        "    def __init__(self, user_tower: UserTower, item_tower: ItemTower):\n",
        "        super().__init__()\n",
        "        self.user_tower = user_tower\n",
        "        self.item_tower = item_tower\n",
        "\n",
        "    def forward(self, data):\n",
        "        user_vector = self.user_tower.get_embedding(data)\n",
        "        item_vector = self.item_tower.get_embedding(data['pos_item'])\n",
        "        return (user_vector * item_vector).sum(dim=1)"
      ],
      "metadata": {
        "id": "l-fw4HLLUOXk"
      },
      "execution_count": 272,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# example_data = next(iter(train_loader))\n",
        "\n",
        "NUM_USERS = len(dataset.encoders['User-ID']) + 1\n",
        "NUM_ISBN = len(dataset.encoders['ISBN']) + 1\n",
        "NUM_TITLES = len(dataset.encoders['Book-Title']) + 1\n",
        "NUM_AUTHORS = len(dataset.encoders['Book-Author']) + 1\n",
        "NUM_PUBLISHERS = len(dataset.encoders['Publisher']) + 1\n",
        "\n",
        "user_tower = UserTower(num_users=NUM_USERS)\n",
        "\n",
        "item_tower = ItemTower(\n",
        "    num_isbn=NUM_ISBN,\n",
        "    num_titles=NUM_TITLES,\n",
        "    num_authors=NUM_AUTHORS,\n",
        "    num_publishers=NUM_PUBLISHERS,\n",
        ")\n",
        "\n",
        "two_towers = TwoTowers(\n",
        "    user_tower,\n",
        "    item_tower\n",
        ").to(device)"
      ],
      "metadata": {
        "id": "jlqHUau8WMjo"
      },
      "execution_count": 273,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "A3QGAbFDa_Lb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Helper Functions"
      ],
      "metadata": {
        "id": "bcsBmPJIb196"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def move_batch_to_device(batch, device):\n",
        "    batch['User-ID'] = batch['User-ID'].to(device)\n",
        "    batch['User-Age'] = batch['User-Age'].to(device)\n",
        "    batch['Rating'] = batch['Rating'].to(device)\n",
        "\n",
        "    for key in batch['pos_item']:\n",
        "        batch['pos_item'][key] = batch['pos_item'][key].to(device)\n",
        "\n",
        "    for neg_item in batch['neg_items']:\n",
        "        for key in neg_item:\n",
        "            neg_item[key] = neg_item[key].to(device)\n",
        "\n",
        "    return batch"
      ],
      "metadata": {
        "id": "w5-fijrXb3Nm"
      },
      "execution_count": 274,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Main Training Loop"
      ],
      "metadata": {
        "id": "Hn06WdV-b4Jf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%rm -rf ./logs/"
      ],
      "metadata": {
        "id": "bGt_U5rrg7eA"
      },
      "execution_count": 275,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import datetime\n",
        "\n",
        "EPOCHS = 100\n",
        "LOG_INTERVAL = 100\n",
        "CLIP_GRAD_NORM = 1.0\n",
        "LEARNING_RATE = 0.001\n",
        "EARLY_STOPPING_PATIENCE = 15\n",
        "TEMPERATURE = 0.05\n",
        "MODEL_SAVE_PATH = \"/content/drive/MyDrive/models\"\n",
        "\n",
        "# loss_fn = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(two_towers.parameters(), lr=LEARNING_RATE)\n",
        "writer = SummaryWriter('./logs/')\n",
        "\n",
        "best_test_loss = float('inf')\n",
        "early_stopping_counter = 0\n",
        "global_step = 0"
      ],
      "metadata": {
        "id": "GlzzNo4_mM0E"
      },
      "execution_count": 276,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "\n",
        "    # -- Main Loop --\n",
        "    running_train_loss = 0.0\n",
        "    two_towers.train()\n",
        "\n",
        "    for batch_idx, batch in enumerate(train_loader):\n",
        "        batch = move_batch_to_device(batch, device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        user_embedding = two_towers.user_tower.get_embedding(batch)  # [B, D]\n",
        "\n",
        "        # Calculate similarity between user and positive example\n",
        "        pos_sim = two_towers(batch)\n",
        "\n",
        "        # Calculate similarity between user and negative examples\n",
        "        #\n",
        "        # Logits (first position will be positive that we want to maximize, and everything else is negative)\n",
        "        # For example, if we have 1 positive example and 1 negative example our logits are:\n",
        "        #   [[pos, neg], ..batch_size..]\n",
        "        #\n",
        "        # Now the label we want cross entropy to maximize is in the 0th position (positive)\n",
        "        #   labels = [0, ..batch_size..]\n",
        "        #\n",
        "        #\n",
        "        neg_sims = []\n",
        "        for neg_item_dict in batch['neg_items']:\n",
        "            neg_emb = two_towers.item_tower.get_embedding(neg_item_dict)  # [B, D]\n",
        "            neg_sim = torch.sum(user_embedding * neg_emb, dim=1)  # [B]\n",
        "            neg_sims.append(neg_sim)\n",
        "\n",
        "        # Contrastive Loss\n",
        "        logits = torch.stack([pos_sim] + neg_sims, dim=1) / TEMPERATURE\n",
        "        labels = torch.zeros(logits.size(0), dtype=torch.long, device=device)\n",
        "        loss = F.cross_entropy(logits, labels)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_train_loss += loss.item()\n",
        "\n",
        "    two_towers.eval()\n",
        "    running_test_loss = 0.0\n",
        "    for batch in test_loader:\n",
        "        batch = move_batch_to_device(batch, device)\n",
        "\n",
        "        pos_sim = two_towers(batch)\n",
        "        user_embedding = two_towers.user_tower.get_embedding(batch)\n",
        "        neg_embedding = two_towers.item_tower.get_embedding(batch['neg_items'][0])\n",
        "        neg_sim = torch.sum(user_embedding * neg_embedding, dim=1)\n",
        "\n",
        "        logits = torch.stack([pos_sim, neg_sim], dim=1) / TEMPERATURE\n",
        "        labels = torch.zeros(logits.size(0), dtype=torch.long, device=device)\n",
        "        loss = F.cross_entropy(logits, labels)\n",
        "\n",
        "        running_test_loss += loss.item()\n",
        "\n",
        "    avg_train_loss = running_train_loss / len(train_loader)\n",
        "    avg_test_loss = running_test_loss / len(test_loader)\n",
        "    print(f\"Epoch {epoch}/{EPOCHS}, Average Training Loss: {avg_train_loss:.4f}, \")\n",
        "    print(f\"Epoch {epoch}/{EPOCHS}, Average Test Loss: {avg_test_loss:.4f}, \")\n",
        "\n",
        "    if batch_idx % 10 == 0:\n",
        "        torch.save(two_towers.state_dict(), f\"{MODEL_SAVE_PATH}/two_towers_good_reads_{datetime.datetime.now().strftime(\"%Y%m%d%S\")}.pt\")\n",
        "\n",
        "\n",
        "writer.close()\n",
        "print(\"Training complete.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UhQ3lphfa_nU",
        "outputId": "d9ac0b31-4212-41bc-94ca-27f63e855d81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100, Average Training Loss: 6.1923, \n",
            "Epoch 1/100, Average Test Loss: 0.9723, \n",
            "Epoch 2/100, Average Training Loss: 3.5858, \n",
            "Epoch 2/100, Average Test Loss: 0.7826, \n",
            "Epoch 3/100, Average Training Loss: 2.9101, \n",
            "Epoch 3/100, Average Test Loss: 0.7363, \n",
            "Epoch 4/100, Average Training Loss: 2.6658, \n",
            "Epoch 4/100, Average Test Loss: 0.7360, \n",
            "Epoch 5/100, Average Training Loss: 2.5447, \n",
            "Epoch 5/100, Average Test Loss: 0.7345, \n",
            "Epoch 6/100, Average Training Loss: 2.4933, \n",
            "Epoch 6/100, Average Test Loss: 0.7210, \n",
            "Epoch 7/100, Average Training Loss: 2.4567, \n",
            "Epoch 7/100, Average Test Loss: 0.7081, \n",
            "Epoch 8/100, Average Training Loss: 2.3840, \n",
            "Epoch 8/100, Average Test Loss: 0.7093, \n",
            "Epoch 9/100, Average Training Loss: 2.3901, \n",
            "Epoch 9/100, Average Test Loss: 0.7125, \n",
            "Epoch 10/100, Average Training Loss: 2.3816, \n",
            "Epoch 10/100, Average Test Loss: 0.7129, \n",
            "Epoch 11/100, Average Training Loss: 2.3632, \n",
            "Epoch 11/100, Average Test Loss: 0.7158, \n",
            "Epoch 12/100, Average Training Loss: 2.3445, \n",
            "Epoch 12/100, Average Test Loss: 0.7051, \n",
            "Epoch 13/100, Average Training Loss: 2.3347, \n",
            "Epoch 13/100, Average Test Loss: 0.7131, \n",
            "Epoch 14/100, Average Training Loss: 2.3103, \n",
            "Epoch 14/100, Average Test Loss: 0.7120, \n",
            "Epoch 15/100, Average Training Loss: 2.2945, \n",
            "Epoch 15/100, Average Test Loss: 0.7120, \n",
            "Epoch 16/100, Average Training Loss: 2.2797, \n",
            "Epoch 16/100, Average Test Loss: 0.7199, \n",
            "Epoch 17/100, Average Training Loss: 2.2994, \n",
            "Epoch 17/100, Average Test Loss: 0.7149, \n",
            "Epoch 18/100, Average Training Loss: 2.2537, \n",
            "Epoch 18/100, Average Test Loss: 0.7176, \n",
            "Epoch 19/100, Average Training Loss: 2.2727, \n",
            "Epoch 19/100, Average Test Loss: 0.7076, \n",
            "Epoch 20/100, Average Training Loss: 2.2348, \n",
            "Epoch 20/100, Average Test Loss: 0.7476, \n",
            "Epoch 21/100, Average Training Loss: 2.2347, \n",
            "Epoch 21/100, Average Test Loss: 0.7192, \n",
            "Epoch 22/100, Average Training Loss: 2.2101, \n",
            "Epoch 22/100, Average Test Loss: 0.7252, \n",
            "Epoch 23/100, Average Training Loss: 2.2050, \n",
            "Epoch 23/100, Average Test Loss: 0.7408, \n",
            "Epoch 24/100, Average Training Loss: 2.2039, \n",
            "Epoch 24/100, Average Test Loss: 0.7321, \n",
            "Epoch 25/100, Average Training Loss: 2.1924, \n",
            "Epoch 25/100, Average Test Loss: 0.7339, \n",
            "Epoch 26/100, Average Training Loss: 2.1631, \n",
            "Epoch 26/100, Average Test Loss: 0.7360, \n",
            "Epoch 27/100, Average Training Loss: 2.1370, \n",
            "Epoch 27/100, Average Test Loss: 0.7313, \n",
            "Epoch 28/100, Average Training Loss: 2.1261, \n",
            "Epoch 28/100, Average Test Loss: 0.7594, \n",
            "Epoch 29/100, Average Training Loss: 2.1366, \n",
            "Epoch 29/100, Average Test Loss: 0.7673, \n",
            "Epoch 30/100, Average Training Loss: 2.0974, \n",
            "Epoch 30/100, Average Test Loss: 0.7579, \n",
            "Epoch 31/100, Average Training Loss: 2.0873, \n",
            "Epoch 31/100, Average Test Loss: 0.7803, \n",
            "Epoch 32/100, Average Training Loss: 2.0645, \n",
            "Epoch 32/100, Average Test Loss: 0.7674, \n",
            "Epoch 33/100, Average Training Loss: 2.0518, \n",
            "Epoch 33/100, Average Test Loss: 0.7630, \n",
            "Epoch 34/100, Average Training Loss: 2.0413, \n",
            "Epoch 34/100, Average Test Loss: 0.7608, \n",
            "Epoch 35/100, Average Training Loss: 1.9862, \n",
            "Epoch 35/100, Average Test Loss: 0.7841, \n",
            "Epoch 36/100, Average Training Loss: 1.9893, \n",
            "Epoch 36/100, Average Test Loss: 0.8181, \n",
            "Epoch 37/100, Average Training Loss: 1.9573, \n",
            "Epoch 37/100, Average Test Loss: 0.7959, \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(two_towers.state_dict(), f\"{MODEL_SAVE_PATH}/two_towers_good_reads_1022.pt\")\n",
        "\n"
      ],
      "metadata": {
        "id": "nViuWOGr_7NE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    # -----------------------\n",
        "    # -- Recall@K Metric --\n",
        "    #\n",
        "    # Work in progress... Implement the recall@k metric to see out of the user's total ratings, how many of these appeared in the top-k.\n",
        "    #\n",
        "\n",
        "    # user_row = next(iter(train_loader))\n",
        "    # user_vector = two_towers.user_tower.get_embedding(user_row)\n",
        "\n",
        "    # scores = torch.matmul(item_vector, user_vector.T)\n",
        "    # scores = scores.T\n",
        "    #\n",
        "    # top_k = 20\n",
        "    # for i, user_id_encoded in enumerate(user_row['User-ID']):\n",
        "    #     top_scores, top_indices = torch.topk(scores[i], top_k)\n",
        "    #     user_id_decoded = dataset.reverse_encoders['User-ID'][user_id_encoded.item()]\n",
        "    #     ground_truth_books = df[df['User-ID'] == user_id_decoded]['ISBN']\n",
        "\n",
        "    #     print(f\"Top k books predicted for user {user_id_decoded}\")\n",
        "    #     print(top_indices)\n",
        "    #     print(f\"Book ratings for user {user_id_decoded}\")\n",
        "    #     print(ground_truth_books)\n",
        "    #\n",
        "    # -----------------------"
      ],
      "metadata": {
        "id": "ZlE4VAFWDDGs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Seeing what the model recommends to me after training\n",
        "\n",
        "- It should have seen me somewhere in the training data and should have learned enough information from the other data to generalize over what I might like.\n",
        "- I will pass my username and age into the User Tower. And then conduct a dot product between my vector and the matrix of learned item embeddings to get relevance scores.\n",
        "- I will then conduct some semi-manual ranking based on removing what I have already read and other info.\n",
        "- Then I will make the final 50 recommendations for me."
      ],
      "metadata": {
        "id": "hlXm69k4dJpF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting all item embeddings\n",
        "entire_dataset = DataLoader(dataset, batch_size=1, shuffle=False)\n",
        "all_item_embeddings = []\n",
        "for batch in entire_dataset:\n",
        "    pos_item = batch['pos_item']\n",
        "    pos_item = {k: v.to(device) for k, v in pos_item.items()}\n",
        "    item_embedding = two_towers.item_tower.get_embedding(pos_item)\n",
        "    all_item_embeddings.append(item_embedding)\n",
        "all_item_embeddings = torch.cat(all_item_embeddings, dim=0)\n",
        "\n",
        "# Getting a single embedding for my learned user\n",
        "paul_user_id = dataset.encoders['User-ID']['1234567890']\n",
        "paul_age = dataset.scalers['Age'].transform([[23]])[0][0]\n",
        "paul_batch = {\n",
        "    'User-ID': torch.tensor([paul_user_id], dtype=torch.long, device=device),\n",
        "    'User-Age': torch.tensor([paul_age], dtype=torch.float32, device=device)\n",
        "}\n",
        "paul_user_embedding = two_towers.user_tower.get_embedding(paul_batch) # [1 batch, 32 dimensions]"
      ],
      "metadata": {
        "id": "KlaJclDBgeeb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculating similarity scores\n",
        "similarity_scores = (paul_user_embedding * all_item_embeddings).sum(dim=1)\n",
        "top_k = 100\n",
        "top_scores, top_indices = torch.topk(similarity_scores, top_k)\n",
        "\n",
        "read_isbns = personal_df['ISBN'].astype(str).to_list()\n",
        "seen_titles = set()\n",
        "unique_recommendations = []\n",
        "\n",
        "for score, idx in zip(top_scores.detach().cpu().numpy(), top_indices.detach().cpu().numpy()):\n",
        "    associated_item = dataset[idx]['pos_item']\n",
        "    title_idx = int(associated_item['Book-Title'])\n",
        "    author_idx = int(associated_item['Book-Author'])\n",
        "    isbn_idx = int(associated_item['Book-ISBN'])\n",
        "\n",
        "    title = dataset.reverse_encoders['Book-Title'][title_idx]\n",
        "    author = dataset.reverse_encoders['Book-Author'][author_idx]\n",
        "    isbn = dataset.reverse_encoders['ISBN'][isbn_idx]\n",
        "\n",
        "    if title in seen_titles:\n",
        "        continue\n",
        "\n",
        "    if isbn in read_isbns:\n",
        "        continue\n",
        "\n",
        "    seen_titles.add(title)\n",
        "    unique_recommendations.append({\n",
        "        'title': title,\n",
        "        'author': author,\n",
        "        'score': score\n",
        "    })"
      ],
      "metadata": {
        "id": "m-w18uL4rmFc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for rec in unique_recommendations[:50]:\n",
        "    print(f\"Title: {rec['title']}, Author: {rec['author']}, Score: {rec['score']:.4f}\")"
      ],
      "metadata": {
        "id": "b6dftVU0rnlP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
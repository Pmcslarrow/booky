{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPd7OnhTskdmHX6+ZSrKOu+"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Importing Dataset"
      ],
      "metadata": {
        "id": "L3c5igSoT9JS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install kagglehub[pandas-datasets]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "kVvdwqPSMaoM",
        "outputId": "2d16c7d3-6d05-41fc-c7f0-4375916e2c1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kagglehub[pandas-datasets] in /usr/local/lib/python3.12/dist-packages (0.3.13)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from kagglehub[pandas-datasets]) (25.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from kagglehub[pandas-datasets]) (6.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from kagglehub[pandas-datasets]) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from kagglehub[pandas-datasets]) (4.67.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from kagglehub[pandas-datasets]) (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas->kagglehub[pandas-datasets]) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->kagglehub[pandas-datasets]) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->kagglehub[pandas-datasets]) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->kagglehub[pandas-datasets]) (2025.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub[pandas-datasets]) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub[pandas-datasets]) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub[pandas-datasets]) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub[pandas-datasets]) (2025.10.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->kagglehub[pandas-datasets]) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "slTaZzDAMLUM",
        "outputId": "d6487be3-23cf-4f01-83f9-0327f03f81bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-591258671.py:19: DeprecationWarning: Use dataset_load() instead of load_dataset(). load_dataset() will be removed in a future version.\n",
            "  books_df = kagglehub.load_dataset(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/arashnic/book-recommendation-dataset?dataset_version_number=3&file_name=Books.csv...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 14.8M/14.8M [00:00<00:00, 46.0MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting zip of Books.csv...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "/usr/local/lib/python3.12/dist-packages/kagglehub/pandas_datasets.py:91: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  result = read_function(\n",
            "/tmp/ipython-input-591258671.py:25: DeprecationWarning: Use dataset_load() instead of load_dataset(). load_dataset() will be removed in a future version.\n",
            "  ratings_df = kagglehub.load_dataset(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Colab cache for faster access to the 'book-recommendation-dataset' dataset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-591258671.py:31: DeprecationWarning: Use dataset_load() instead of load_dataset(). load_dataset() will be removed in a future version.\n",
            "  users_df = kagglehub.load_dataset(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Colab cache for faster access to the 'book-recommendation-dataset' dataset.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from collections import Counter\n",
        "from google.colab import drive\n",
        "import kagglehub\n",
        "from kagglehub import KaggleDatasetAdapter\n",
        "drive.mount('/content/drive/')\n",
        "\n",
        "# Load the latest version\n",
        "books_df = kagglehub.load_dataset(\n",
        "  KaggleDatasetAdapter.PANDAS,\n",
        "  \"arashnic/book-recommendation-dataset\",\n",
        "  \"Books.csv\",\n",
        ")\n",
        "\n",
        "ratings_df = kagglehub.load_dataset(\n",
        "  KaggleDatasetAdapter.PANDAS,\n",
        "  \"arashnic/book-recommendation-dataset\",\n",
        "  \"Ratings.csv\",\n",
        ")\n",
        "\n",
        "users_df = kagglehub.load_dataset(\n",
        "  KaggleDatasetAdapter.PANDAS,\n",
        "  \"arashnic/book-recommendation-dataset\",\n",
        "  \"Users.csv\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_ratings_books = pd.merge(ratings_df, books_df, on=\"ISBN\", how='inner')\n",
        "df = pd.merge(df_ratings_books, users_df, on='User-ID')\n",
        "df['User-ID'] = df['User-ID'].astype(str)\n",
        "df['Year-Of-Publication'] = pd.to_numeric(df['Year-Of-Publication'], errors='coerce')\n",
        "df = df.dropna(subset=['Year-Of-Publication'])\n",
        "df = df.dropna(subset=['Age'])\n",
        "df = df[df['Book-Rating'] > 0]\n",
        "df['Book-Rating'].describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        },
        "id": "93r6ilG_NQPw",
        "outputId": "a393fd16-a557-4724-d755-0efe297bdbe7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    269620.000000\n",
              "mean          7.736162\n",
              "std           1.814530\n",
              "min           1.000000\n",
              "25%           7.000000\n",
              "50%           8.000000\n",
              "75%           9.000000\n",
              "max          10.000000\n",
              "Name: Book-Rating, dtype: float64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Book-Rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>269620.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>7.736162</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.814530</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>7.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>8.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>9.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>10.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> float64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df['Book-Rating'].value_counts().sort_index())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_kxkPFigfCob",
        "outputId": "f8048695-c155-4886-ec80-b05cf73fc5fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Book-Rating\n",
            "1       886\n",
            "2      1562\n",
            "3      3331\n",
            "4      5096\n",
            "5     27744\n",
            "6     21445\n",
            "7     45538\n",
            "8     64824\n",
            "9     45251\n",
            "10    53943\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler, MultiLabelBinarizer\n",
        "import ast\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# User Tower -- User-ID, Age\n",
        "# Item Tower -- ISBN, Book-Title, Book-Author, Publisher, Year-Of-Publication\n",
        "\n",
        "class BookRecommenderDataset(Dataset):\n",
        "    def __init__(self, data):\n",
        "        self.data = data.sample(frac=0.05, random_state=42)\n",
        "        self.data = self.preprocess(self.data)\n",
        "\n",
        "    def preprocess(self, data):\n",
        "        self.encoders = {}\n",
        "        self.scalers = {}\n",
        "\n",
        "        label_encoders = ['User-ID', 'ISBN', 'Book-Title', 'Book-Author', 'Publisher']\n",
        "        standard_scalers = ['Age', 'Year-Of-Publication']\n",
        "\n",
        "        for key in label_encoders:\n",
        "            self.encoders[key] = LabelEncoder()\n",
        "            data[key] = self.encoders[key].fit_transform(data[key].astype(str))\n",
        "\n",
        "        for key in standard_scalers:\n",
        "            self.scalers[key] = StandardScaler()\n",
        "            data[[key]] = self.scalers[key].fit_transform(data[[key]])\n",
        "        return data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = self.data.iloc[idx]\n",
        "        return {\n",
        "            'User-ID': torch.tensor(item['User-ID'], dtype=torch.long),\n",
        "            'User-Age': torch.tensor(item['Age'], dtype=torch.float32),\n",
        "            'Book-ISBN': torch.tensor(item['ISBN'], dtype=torch.long),\n",
        "            'Book-Title': torch.tensor(item['Book-Title'], dtype=torch.long),\n",
        "            'Book-Author': torch.tensor(item['Book-Author'], dtype=torch.long),\n",
        "            'Book-Publisher': torch.tensor(item['Publisher'], dtype=torch.long),\n",
        "            'Book-Year-Of-Publication': torch.tensor(item['Year-Of-Publication'], dtype=torch.float32),\n",
        "            'Rating': torch.tensor(item['Book-Rating'], dtype=torch.float32)\n",
        "        }\n",
        "\n",
        "dataset = BookRecommenderDataset(df)\n"
      ],
      "metadata": {
        "id": "hzV4YkTNPSuc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_size = int(0.5 * len(dataset))\n",
        "test_size = len(dataset) - train_size\n",
        "train_data, test_data = random_split(dataset, [train_size, test_size])\n",
        "\n",
        "# Dataloaders\n",
        "train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_data, batch_size=64, shuffle=False)"
      ],
      "metadata": {
        "id": "5UuengF0Tojk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "next(iter(train_loader))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vznGD0IGTxA7",
        "outputId": "386a2d6d-0f70-4979-dd4b-ae51e5b93b5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'User-ID': tensor([2487, 5638,  453, 1151, 5914, 4037, 6156, 2890, 5895,  758, 1145, 1618,\n",
              "         4024, 2685, 4771, 3671, 4861, 6729, 1738, 5705, 4769, 1996, 1463, 5160,\n",
              "         5887,  566, 1075, 3619, 4024, 4610,  363, 1619, 4523, 4798, 2585, 2580,\n",
              "         6718, 3958, 5002, 1463,  848, 2571,   93, 4642, 1754, 3593, 1153,  563,\n",
              "          838, 1968, 5435, 2516, 2004, 5944, 6171, 2298, 3087, 2763,    9, 6189,\n",
              "         4257, 6718, 1128,  748]),\n",
              " 'User-Age': tensor([ 0.6693,  0.8166,  1.8474, -0.0670,  0.3012,  0.5957, -1.7605,  0.3012,\n",
              "          0.3748,  1.1111, -1.0242,  2.5838,  0.4485, -1.3187,  0.8166, -1.4660,\n",
              "         -0.9505, -1.0978, -0.8033, -0.5088,  0.5221,  1.1848,  0.5221,  0.3748,\n",
              "          1.5529,  0.2276,  0.8902,  0.6693,  0.4485,  0.9639, -0.0670,  0.0067,\n",
              "          0.4485, -0.2142, -0.8033,  2.2892,  1.1111, -0.4351, -0.1406,  0.5221,\n",
              "          0.5221,  2.3629, -0.9505,  0.0067, -0.5824,  0.5957,  1.6266, -2.1286,\n",
              "         -1.3923, -0.5088, -0.4351, -1.0242, -0.5824, -1.3923,  0.2276, -0.5824,\n",
              "         -0.4351,  0.6693, -0.3615, -0.5824, -0.3615,  1.1111,  1.0375, -0.2142]),\n",
              " 'Book-ISBN': tensor([ 3269,  2697,  6631,  1483,   657,  2259,  5522,  1565,  6629,  8016,\n",
              "         10257,  8345,  1149,  1912,  4174,  9207,  2609,  6877,  8542,  8577,\n",
              "         10799,  9238,  2402,  2022,  3609, 10535,  4374,  5613,  1812,  5440,\n",
              "          3354,  1667,  1595,  9328,  8495,  3168,  7705,  5495,   211,  1591,\n",
              "          5271,  4534, 10570,  2744,  2257, 10992,  5794,  4496, 10308,  2479,\n",
              "          2393,  9028,  5097,  3971,  4850,  7002,  9606,  5258,   788,  7298,\n",
              "          8878,  1375, 10076,  7085]),\n",
              " 'Book-Title': tensor([ 3076,  8114,  5338,  1998,  5146, 10021,  4864,  6835,   552,  9948,\n",
              "          5960,  6099,  1064,  3414,  8921, 10663,  8823,  5021,  7368,  6164,\n",
              "          2038, 10495,  4812,  7024,  3676,  3626,  8052,  7218,  1874,  7439,\n",
              "          3338,  8738,  9332, 10555,  4158,  5431,  3228,  3811,  8118,  9774,\n",
              "           582,  3384,  5682,  8661,  9748,  5530,  4014,   714,  4586,  4617,\n",
              "          2520,  3232,  4969,  9359,  6755,  6029,  8637,   429,  9579,  3903,\n",
              "          7509,  1014,  1036,    52]),\n",
              " 'Book-Author': tensor([4765,   41, 4530, 2342,  461,  884, 5375, 2917, 1636, 2519, 2775, 5878,\n",
              "         1393, 3357, 6258, 5718, 5234,  510,  942, 5141, 5340, 5417, 1574, 4050,\n",
              "         1484, 1803, 6409, 5537,  368, 2120, 5225,  170,  963, 2962,  679, 5008,\n",
              "         6117, 1435, 5396, 1579, 3990, 2829, 6343, 6514, 5836, 6679, 1844, 4776,\n",
              "         5060,  391, 1824, 3112, 6703, 2722,  934,  801, 3905, 4691, 1233, 5496,\n",
              "         4393, 1644, 1705, 4144]),\n",
              " 'Book-Publisher': tensor([1867, 1848, 1884, 1750, 1758,  741, 1617, 1650, 1600,  713,  661,  656,\n",
              "         1262,  151,   18, 1713, 1279, 1850, 1780,  477, 1076, 1745, 1596,  151,\n",
              "          194,  495, 1876,  399,  150,  156, 1445, 1021, 1650, 1138,   87, 1172,\n",
              "         1750,  156,  767, 1652, 1254,  609,  686,  752,  741, 1136,  156,  710,\n",
              "          966, 1596,  741, 1463,  487,  439, 1238, 1566,   52,  924, 1300,   87,\n",
              "          427, 1651,  332,   12]),\n",
              " 'Book-Year-Of-Publication': tensor([ 0.1333,  0.1503,  0.1375,  0.1375, -8.3820,  0.1205,  0.0907,  0.1461,\n",
              "          0.0992,  0.0822,  0.1248,  0.1077,  0.1333,  0.0864,  0.0822,  0.1418,\n",
              "          0.1461,  0.1120,  0.1503,  0.1375,  0.1120,  0.1546,  0.1120,  0.1205,\n",
              "          0.1035,  0.1333,  0.1248,  0.1035,  0.0609,  0.0566, -0.0286,  0.1461,\n",
              "          0.1546,  0.1205,  0.1205,  0.1461,  0.1546,  0.0694,  0.1461,  0.1503,\n",
              "          0.1077,  0.1035,  0.1205,  0.1162,  0.1205,  0.1162,  0.1375,  0.1461,\n",
              "          0.0864,  0.1333,  0.1461,  0.0694,  0.1077,  0.1333,  0.0992,  0.1205,\n",
              "          0.1461,  0.1503,  0.1077,  0.1375,  0.1248,  0.1546,  0.1333,  0.1248]),\n",
              " 'Rating': tensor([ 8.,  9.,  7.,  9.,  8.,  8.,  6.,  9.,  8., 10.,  6.,  8.,  9., 10.,\n",
              "         10., 10.,  6.,  6.,  9.,  8.,  7.,  3., 10.,  7.,  6.,  7.,  9.,  9.,\n",
              "         10.,  9.,  5.,  8.,  8.,  6., 10.,  8., 10.,  7.,  4.,  6.,  8.,  9.,\n",
              "          9.,  8.,  6.,  6.,  4.,  7.,  9.,  9., 10.,  9., 10.,  9.,  9.,  9.,\n",
              "          6.,  7.,  7., 10.,  9., 10.,  7., 10.])}"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Two Tower Model for Recommendations"
      ],
      "metadata": {
        "id": "qjn33eipT_-e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class UserTower(nn.Module):\n",
        "\n",
        "    # User Tower -- User-ID, Age\n",
        "\n",
        "    def __init__(self, num_users, embedding_dim=32):\n",
        "        super().__init__()\n",
        "        self.user_embedding = nn.Embedding(num_users, embedding_dim, padding_idx=0)\n",
        "\n",
        "        self.user_mlp = nn.Sequential(\n",
        "            nn.Linear(embedding_dim + 1, 128), # 1 embedding + 1 numerical\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, embedding_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, user_id, age):\n",
        "        \"\"\"\n",
        "        user_id: (batch,) int64\n",
        "        review_mean: (batch,) float32\n",
        "        \"\"\"\n",
        "        user_emb = self.user_embedding(user_id)\n",
        "        age = age.unsqueeze(1)\n",
        "        x = torch.cat([user_emb, age], dim=1)\n",
        "        return self.user_mlp(x)\n",
        "\n",
        "    def get_embedding(self, data):\n",
        "        return self.forward(data['User-ID'], data['User-Age'])\n"
      ],
      "metadata": {
        "id": "J4Rh2nDqUCxf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ItemTower(nn.Module):\n",
        "    def __init__(self, num_isbn, num_titles, num_authors, num_publishers, embedding_dim=32):\n",
        "        super().__init__()\n",
        "\n",
        "        # Item Tower -- ISBN, Book-Title, Book-Author, Publisher, Year-Of-Publication\n",
        "\n",
        "        self.book_isbn_embedding = nn.Embedding(num_isbn, embedding_dim, padding_idx=0)\n",
        "        self.book_title_embedding = nn.Embedding(num_titles, embedding_dim, padding_idx=0)\n",
        "        self.book_author_embedding = nn.Embedding(num_authors, embedding_dim, padding_idx=0)\n",
        "        self.book_publisher_embedding = nn.Embedding(num_publishers, embedding_dim, padding_idx=0)\n",
        "\n",
        "        self.item_mlp = nn.Sequential(\n",
        "            nn.Linear(embedding_dim * 4 + 1, 128),  # 4 embeddings + 1 numerical\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, embedding_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, isbn, book_title, book_author, book_publisher, book_year_of_publication):\n",
        "        book_isbn_emb = self.book_isbn_embedding(isbn)\n",
        "        book_title_emb = self.book_title_embedding(book_title)\n",
        "        book_author_emb = self.book_author_embedding(book_author)\n",
        "        book_publisher_emb = self.book_publisher_embedding(book_publisher)\n",
        "        book_year = book_year_of_publication.unsqueeze(1)\n",
        "\n",
        "        x = torch.cat([\n",
        "            book_isbn_emb,\n",
        "            book_title_emb,\n",
        "            book_author_emb,\n",
        "            book_publisher_emb,\n",
        "            book_year\n",
        "        ], dim=1)\n",
        "\n",
        "        return self.item_mlp(x)\n",
        "\n",
        "    def get_embedding(self, data):\n",
        "        return self.forward(\n",
        "            data['Book-ISBN'],\n",
        "            data['Book-Title'],\n",
        "            data['Book-Author'],\n",
        "            data['Book-Publisher'],\n",
        "            data['Book-Year-Of-Publication'],\n",
        "        )\n"
      ],
      "metadata": {
        "id": "hLSZeUSEUNBY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TwoTowers(nn.Module):\n",
        "    def __init__(self, user_tower: UserTower, item_tower: ItemTower):\n",
        "        super().__init__()\n",
        "        self.user_tower = user_tower\n",
        "        self.item_tower = item_tower\n",
        "\n",
        "    def forward(self, data):\n",
        "        user_vector = self.user_tower.get_embedding(data)\n",
        "        item_vector = self.item_tower.get_embedding(data)\n",
        "        return (user_vector * item_vector).sum(dim=1)"
      ],
      "metadata": {
        "id": "l-fw4HLLUOXk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_data = next(iter(train_loader))\n",
        "\n",
        "NUM_USERS = len(dataset.encoders['User-ID'].classes_)\n",
        "NUM_ISBN = len(dataset.encoders['ISBN'].classes_)\n",
        "NUM_TITLES = len(dataset.encoders['Book-Title'].classes_)\n",
        "NUM_AUTHORS = len(dataset.encoders['Book-Author'].classes_)\n",
        "NUM_PUBLISHERS = len(dataset.encoders['Publisher'].classes_)\n",
        "\n",
        "user_tower = UserTower(num_users=NUM_USERS)\n",
        "\n",
        "item_tower = ItemTower(\n",
        "    num_isbn=NUM_ISBN,\n",
        "    num_titles=NUM_TITLES,\n",
        "    num_authors=NUM_AUTHORS,\n",
        "    num_publishers=NUM_PUBLISHERS,\n",
        ")\n",
        "\n",
        "two_towers = TwoTowers(\n",
        "    user_tower,\n",
        "    item_tower\n",
        ")"
      ],
      "metadata": {
        "id": "jlqHUau8WMjo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "A3QGAbFDa_Lb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Helper Functions"
      ],
      "metadata": {
        "id": "bcsBmPJIb196"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Training Helpers ---\n",
        "def train_one_epoch(model, loader, optimizer, loss_fn):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for batch_idx, data in enumerate(loader):\n",
        "        optimizer.zero_grad()\n",
        "        preds = model(data)\n",
        "        targets = data['Rating']\n",
        "        loss = loss_fn(preds, targets)\n",
        "\n",
        "        # Sanity checks\n",
        "        assert not torch.isnan(preds).any(), \"NaN in predictions\"\n",
        "        assert not torch.isnan(targets).any(), \"NaN in targets\"\n",
        "        assert not torch.isinf(preds).any(), \"Inf in predictions\"\n",
        "        assert not torch.isinf(targets).any(), \"Inf in targets\"\n",
        "\n",
        "        loss.backward()\n",
        "        # torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=CLIP_GRAD_NORM)\n",
        "        optimizer.step()\n",
        "\n",
        "        yield batch_idx, loss.item()\n",
        "\n",
        "@torch.no_grad()\n",
        "def calculate_test_loss(model, test_loader, loss_fn):\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "    num_batches = 0\n",
        "\n",
        "    for data in test_loader:\n",
        "        preds = model(data)\n",
        "        targets = data['Rating']\n",
        "        loss = loss_fn(preds, targets)\n",
        "        total_loss += loss.item()\n",
        "        num_batches += 1\n",
        "\n",
        "    return total_loss / num_batches if num_batches > 0 else float('inf')\n",
        "\n",
        "def evaluate_and_checkpoint(model, epoch, global_step, best_loss, counter, test_loader, loss_fn):\n",
        "    test_loss = calculate_test_loss(model, test_loader, loss_fn)\n",
        "\n",
        "    if test_loss < best_loss:\n",
        "        best_loss = test_loss\n",
        "        counter = 0\n",
        "        timestamp = datetime.datetime.now().strftime('%Y%m%d')\n",
        "        save_path = f\"{MODEL_SAVE_PATH}/two_towers_best_model_{timestamp}.pt\"\n",
        "        torch.save(model.state_dict(), save_path)\n",
        "        print(f\"[Epoch {epoch}] ✅ Improved! Test Loss: {test_loss:.4f}. Model saved.\")\n",
        "    else:\n",
        "        counter += 1\n",
        "        print(f\"[Epoch {epoch}] No improvement. Test Loss: {test_loss:.4f} ({counter}/{EARLY_STOPPING_PATIENCE})\")\n",
        "\n",
        "    return best_loss, counter"
      ],
      "metadata": {
        "id": "w5-fijrXb3Nm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Main Training Loop"
      ],
      "metadata": {
        "id": "Hn06WdV-b4Jf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%rm -rf ./logs/"
      ],
      "metadata": {
        "id": "bGt_U5rrg7eA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import datetime\n",
        "\n",
        "EPOCHS = 200\n",
        "LOG_INTERVAL = 100\n",
        "CLIP_GRAD_NORM = 1.0\n",
        "LEARNING_RATE = 0.001\n",
        "EARLY_STOPPING_PATIENCE = 15\n",
        "MODEL_SAVE_PATH = \"/content/drive/MyDrive/models\"\n",
        "\n",
        "loss_fn = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(two_towers.parameters(), lr=LEARNING_RATE)\n",
        "writer = SummaryWriter('./logs/')\n",
        "\n",
        "best_test_loss = float('inf')\n",
        "early_stopping_counter = 0\n",
        "global_step = 0\n",
        "\n",
        "all_items_loader = DataLoader(dataset, batch_size=len(dataset), shuffle=False)\n",
        "items = next(iter(all_items_loader))\n",
        "item_vector = two_towers.item_tower.get_embedding(items)"
      ],
      "metadata": {
        "id": "GlzzNo4_mM0E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "\n",
        "    # -- Main Loop --\n",
        "    running_loss = 0.0\n",
        "    two_towers.train()\n",
        "\n",
        "    for batch_idx, batch in enumerate(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        preds = two_towers(batch)\n",
        "        targets = batch['Rating']\n",
        "        loss = loss_fn(preds, targets)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    avg_loss = running_loss / len(train_loader)\n",
        "    print(f\"Epoch {epoch}, Average Training Loss (based on rating): {avg_loss:.4f}\")\n",
        "\n",
        "\n",
        "    # -- Recall@K Metric --\n",
        "    user_row = next(iter(train_loader))\n",
        "    user_vector = two_towers.user_tower.get_embedding(user_row)\n",
        "\n",
        "    scores = torch.matmul(item_vector, user_vector.T)\n",
        "    scores = scores.T\n",
        "\n",
        "    top_k = 50\n",
        "    for i, user_id in enumerate(user_row['User-ID']):\n",
        "        top_scores, top_indices = torch.topk(scores[i], top_k)\n",
        "\n",
        "        print(top_indices)\n",
        "        break\n",
        "\n",
        "\n",
        "\n",
        "    print(f\"Epoch {epoch}/{EPOCHS} completed.\")\n",
        "\n",
        "writer.close()\n",
        "print(\"Training complete.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 490
        },
        "id": "UhQ3lphfa_nU",
        "outputId": "f4d2ad53-605d-4ec1-e10c-98309a5c89b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Average Training Loss (based on rating): 0.0811\n",
            "tensor([ 2515,  6097,  1115,  8632,  7310,  7222,  4206,  8718,   553,   676,\n",
            "         3775,   896, 13282,   163, 10866,  5071, 12279, 11630,  5724,  2833,\n",
            "           80,   256,  4951, 11940,   193,  5153, 13167, 12182,  8040,  6120,\n",
            "           32,  5892,  9656, 12569,  8843, 12365,   121,  1407,  5878,  4781,\n",
            "        10196,  7990, 10715,  7028,  2315,   429,  2427, 13313,  4203,  7947])\n",
            "Epoch 1/200 completed.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-252327567.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    645\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m             )\n\u001b[0;32m--> 647\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    648\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    355\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    827\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    828\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 829\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    830\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}